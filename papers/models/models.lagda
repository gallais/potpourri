%%%%% Pick one of the three
%\include{articleheader}
%\include{sigplanheader}
\include{lncsheader}
%%%%
\usepackage{mathpartir}
\include{commands}

\begin{document}
\title{Type and Scope Preserving Semantics}
\maketitle{}

\begin{abstract}
We introduce a notion of type and scope preserving semantics
generalising Goguen and McKinna's approach to defining one traversal
generic enough to be instantiated to renaming first and
then substitution. Its careful distinction of environment and
model values as well as its variation on a structure typical of
a Kripke semantics make it capable of expressing renaming and
substitution but also various forms of Normalisation by Evaluation
as well as, perhaps more surprisingly, monadic computations such
as a printing function.

We then demonstrate that expressing these algorithms in a common
framework yields immediate benefits: we can deploy some logical
relations generically over these instances and obtain for instance
the fusion lemmas for renaming, substitution and normalisation by
evaluation as simple corollaries of the appropriate fundamental
lemma.
\end{abstract}

\section*{Introduction}

In order to implement an embedded Domain Specific Language (eDSL)~\cite{hudak1996building},
a developer can opt for either a shallow or a deep
embedding~\cite{svenningsson2013combining,gill2014domain}. In the shallow approach, she
will use the host language's own types and term constructs to model the domain
specific language's building blocks. This will allow her to rely on any and all
of the host's libraries when writing programs in the eDSL. Should she decide
to use a deep embedding, representing expressions directly as their abstract
syntax tree will allow her to inspect, optimise, and compile terms as she sees
fit. This ability to inspect the tree comes at the cost of having to reimplement
basic notions such as renaming or substitution with the risk of introducing
bugs. Trying to get the compiler to detect these bugs leads to a further
distinction between different kinds of deep embeddings: she may either prove type
and scope safety on paper and use an inductive \emph{type} to describe an \emph{untyped}
syntax, follow Carette, Kiselyov, and Shan~\cite{carette2009finally} and rely on
parametric polymorphism to guarantee the existence of an underlying type and scope
safe term, or use an inductive \emph{family} to represent the term itself whilst
enforcing these invariants in its indices.

Goguen and McKinna's Candidates for Substitution~\cite{goguen1997candidates}
begot work by McBride~\cite{mcbride2005type} and Benton, Hur, Kennedy and
McBride~\cite{benton2012strongly} showing how to alleviate the programmer's
burden when she opts for the strongly-typed approach based on inductive families
in Epigram~\cite{mcbride2004view} and Coq~\cite{Coq:manual} respectively. They
both define a traversal generic enough to be instantiated to renaming
first and then substitution. In Benton et al., the bulk of the work has to be
repeated when defining Normalisation by Evaluation. Reasoning about these definitions
is also still mostly done in an ad-hoc manner: Coq's tactics do help them discharge
the four fusion lemmas involving renaming and substitution but the properties of
the evaluation function are established using some more proof scripts and rely
on function extensionality rather than the usual Partial Equivalence Relation
we use.

We build on their insights and define an abstract notion of \AR{Semantics}
encompassing these two important operations as well as others Carette et al.
could represent (e.g. measuring the size of a term) and even Normalisation
by Evaluation~\cite{berger1991inverse}. By highlighting the common structure
of all of these algorithms, we get the opportunity to not only implement
them but also prove their properties generically.

\paragraph{Outline} We shall start by defining the simple calculus we will use
as a running example. We will then introduce a notion of environments as well
as one well-known instance: the preorder of context inclusions. This will lead
us to defining a generic notion of type and scope-preserving \AR{Semantics} which
can be used to define a generic evaluation function. We will then showcase the
ground covered by these \AR{Semantics}: from the syntactic ones corresponding
to renaming and substitution to printing with names or some variations on Normalisation
by Evaluation. Finally, we will demonstrate how, the definition of \AR{Semantics}
being generic enough, we can prove fundamental lemmas about these evaluation
functions: we characterise the semantics which are synchronisable and give an
abstract treatment of composition yielding compaction and reuse of proofs
compared to Benton et al.~\cite{benton2012strongly}

\paragraph{Notations} This article is a literate Agda file typeset using the
\LaTeX{} backend with as little post-processing as possible: we simply hide
telescopes of implicit arguments as well as \APT{Set} levels and properly display (super / sub)-scripts
as well as special operators such as \AF{>>=} or \AF{++}. As such, a lot of
the notations have a meaning in Agda: \AIC{green} identifiers are data constructors,
\ARF{pink} names refer to record fields, and \AF{blue} is characteristic of
defined symbols. Underscores have a special status: when defining mixfix
identifiers~\cite{danielsson2011parsing}, they mark positions where arguments
may be inserted; our using the development version of Agda means that we have
access to Haskell-style sections i.e. one may write \AF{\_+} \AN{5} for the partial
application of \AF{\_+\_} corresponding to \AS{Î»} x \AS{â†’} \AB{x} \AF{+} \AN{5}
or, to mention something that will appear later on, \AF{Renaming} \AF{âŠ¨âŸ¦\_âŸ§\_}
for the partial applications of \AF{\_âŠ¨âŸ¦\_âŸ§\_} to \AF{Renaming}.

\paragraph{Formalisation} This whole development has been checked by Agda~\cite{norell2009dependently}
which guarantees that all constructions are indeed well-typed, and all functions are
total. Nonetheless, it should be noted that the generic model constructions and the
various example of \AR{Semantics} given can be fully replicated in Haskell using GADTs
to describe both the terms themselves and the singletons~\cite{eisenberg2013dependently}
providing the user with the runtime descriptions of their types or their contexts' shapes.
This yields, to the best of our knowledge, the first tagless and typeful implementation
of Normalisation by Evaluation in Haskell. The subtleties of working with dependent types
in Haskell~\cite{lindley2014hasochism} are outside the scope of this paper but we do
provide a (commented) Haskell module containing all the translated definitions.
It should be noted that Danvy, Keller and Puech have achieved a similar goal in
OCaml~\cite{danvytagless} but their formalisation uses Parametric Higher Order Abstract
Syntax~\cite{chlipala2008parametric} which frees them from having to deal with variable binding, contexts and use
models Ã  la Kripke where one may extend the context. However we consider these to be
primordial given that they can still guide the implementation of more complex type
theories where, until now, being typeful is still out of reach but type-level guarantees
about scope preservation still help to root out a lot of bugs.


\AgdaHide{
\begin{code}
{-# OPTIONS --no-eta #-}
module models where

open import Level using (Level ; _âŠ”_)
open import Data.Empty
open import Data.Unit renaming (tt to âŸ¨âŸ©)
open import Data.Bool
open import Data.Sum hiding (map ; [_,_])
open import Data.Product hiding (map)
open import Function

infixr 1 _$â€²_
_$â€²_ : {A B : Set} (f : A â†’ B) (a : A) â†’ B
_$â€²_ = _$_
\end{code}}

\section{The Calculus}

We are going to define and study various semantics for a simply-typed Î»-calculus
with \AIC{`Bool} and \AIC{`Unit} as base types as a minimal example of a sum type
and a record type equipped with an Î·-rule.

\AgdaHide{
\begin{code}
infixr 20 _`â†’_
\end{code}}
\begin{code}
data ty : Set where
  `Unit  : ty
  `Bool  : ty
  _`â†’_   : (Ïƒ Ï„ : ty) â†’ ty
\end{code}

In order to be able to talk about the type of the variables in scope, we
need a notion of contexts. We choose to represent them as snoc lists of
types; \AIC{Îµ} denotes the empty context and \AB{Î“} \AIC{âˆ™} \AB{Ïƒ} the
context \AB{Î“} extended with a fresh variable of type \AB{Ïƒ}. Variables
are then positions in such a context represented as typed de Bruijn
indices~\cite{de1972lambda}.

\AgdaHide{
\begin{code}
infixl 10 _âˆ™_
infix 5 _âˆˆ_
\end{code}}
\begin{code}
data Con : Set where
  Îµ    : Con
  _âˆ™_  : (Î“ : Con) (Ïƒ : ty) â†’ Con

infixr 5 1+_
data _âˆˆ_ (Ïƒ : ty) : (Î“ : Con) â†’ Set where
  zero  : {Î“ : Con} â†’ Ïƒ âˆˆ (Î“ âˆ™ Ïƒ)
  1+_   : {Î“ : Con} {Ï„ : ty} (pr : Ïƒ âˆˆ Î“) â†’ Ïƒ âˆˆ (Î“ âˆ™ Ï„)
\end{code}

The syntax for this Î»-calculus is designed to guarantee that terms are
well-scoped and well-typed by construction. This presentation due to
Altenkirch and Reus~\cite{altenkirch1999monadic} relies heavily on
Dybjer's inductive families~\cite{dybjer1991inductive}. Rather than
having untyped pre-terms and a typing relation assigning a type to
them, the rules are here enforced in the syntax: we can see for example
that the \AIC{`var} constructor takes a typed de Bruijn index and
constructs a term of the corresponding type; that application (\AIC{\_`\$\_})
takes a function from \AB{Ïƒ} to \AB{Ï„}, an argument of type \AB{Ïƒ} living
in the same scope \AB{Î“} and produces a term of type \AB{Ï„}; or that the
body of a Î»-abstraction (\AIC{`Î»}) has its context extended with a fresh
variable whose type corresponds to the domain of the function being defined.


\AgdaHide{
\begin{code}
open import Data.Nat as â„• using (â„• ; _+_)

size : Con â†’ â„•
size Îµ        = 0
size (Î“ âˆ™ _)  = 1 + size Î“

infix 5 _âŠ¢_
infixl 5 _`$_
\end{code}}
\begin{code}
data _âŠ¢_ (Î“ : Con) : (Ïƒ : ty) â†’ Set where
  `var   : {Ïƒ : ty} (v : Ïƒ âˆˆ Î“) â†’ Î“ âŠ¢ Ïƒ
  _`$_   : {Ïƒ Ï„ : ty} (t : Î“ âŠ¢ (Ïƒ `â†’ Ï„)) (u : Î“ âŠ¢ Ïƒ) â†’ Î“ âŠ¢ Ï„
  `Î»     : {Ïƒ Ï„ : ty} (t : Î“ âˆ™ Ïƒ âŠ¢ Ï„) â†’ Î“ âŠ¢ (Ïƒ `â†’ Ï„)
  `âŸ¨âŸ©    : Î“ âŠ¢ `Unit
  `tt    : Î“ âŠ¢ `Bool
  `ff    : Î“ âŠ¢ `Bool
  `ifte  : {Ïƒ : ty} (b : Î“ âŠ¢ `Bool) (l r : Î“ âŠ¢ Ïƒ) â†’ Î“ âŠ¢ Ïƒ
\end{code}

\section{A Generic Notion of Environment}

All the semantics we are interested in defining evaluate a term
written in the type-correct representation of the calculus defined
above given an interpretation of its free variables. We call the
collection of these interpretations of type \AB{R} for the variables
in scope an \AB{R}-(evaluation) environment (and leave out \AB{R}
when it is easily inferred from the context). Because the content of
environments may vary wildly between different semantics (e.g. renaming
environments contain variables whilst the normalisation by evaluation ones
carry elements of the model) whilst their structure stays the same,
we define the notion generically. Formally, this translates to
\AB{R}-environments being the pointwise lifting of the relation
\AB{R} between contexts and types to a relation between two contexts.

Rather than using a datatype to represent such a lifting, we choose
to use a function space. This decision is based on Jeffrey's observation
that one can obtain associativity of append for free by using difference
lists~\cite{jeffrey2011assoc}. In our case the interplay between various
combinators (e.g. \AF{refl} and \AF{trans}) defined later on is vastly
simplified by this rather simple decision.

\AgdaHide{
\begin{code}
infix 5 _[_]_
\end{code}}
\begin{code}
_[_]_ :  {â„“ : Level} (Î” : Con) (R : (Î” : Con) (Ïƒ : ty) â†’ Set â„“) (Î“ : Con) â†’ Set â„“
Î” [ R ] Î“ = (Ïƒ : ty) (v : Ïƒ âˆˆ Î“) â†’ R Î” Ïƒ
\end{code}

\AgdaHide{
\begin{code}
infixl 10 [_]_`âˆ™_
\end{code}}

For a fixed context \AB{Î”} and relation \AB{R}, these environments can
be built step by step by noticing that the environment corresponding to
an empty context is trivial and that one may extend and already existing
environment provided a proof of the right type. In concrete cases, there
will be no sensible way to infer \AB{R} when using the second combinator
hence our decision to make it possible to tell Agda which relation we are
working with.

\begin{code}
`Îµ : {â„“ : Level} {Î” : Con} {R : (Î” : Con) (Ïƒ : ty) â†’ Set â„“} â†’ Î” [ R ] Îµ
`Îµ = Î» _ ()

[_]_`âˆ™_ :  {â„“ : Level} {Î“ Î” : Con} (R : (Î” : Con) (Ïƒ : ty) â†’ Set â„“) {Ïƒ : ty}
           (Ï : Î” [ R ] Î“) (s : R Î” Ïƒ) â†’ Î” [ R ] (Î“ âˆ™ Ïƒ)
([ R ] Ï `âˆ™ s) _ zero    = s
([ R ] Ï `âˆ™ s) Ïƒ (1+ n)  = Ï Ïƒ n
\end{code}

\subsubsection{The Preorder of Renamings}
\label{preorder}

A key instance of environments which will play a predominant role
in this paper is the notion of renaming. The reader may be accustomed
to the more restrictive notion of context inclusions as described
by order preserving embedding~\cite{altenkirch1995categorical}.
Writing non-injective or non-order preserving renamings would take
perverse effort given that we implement generic interpretations. In
practice, the only combinators we use do guarantee that all the
renamings we generate are context inclusions. As a consequence, we
will use the two expressions interchangeably from now on.

A context inclusion \AB{Î“} \AF{âŠ†} \AB{Î”} is an environment pairing
each variable of type \AB{Ïƒ} in \AB{Î“} to one of the same type in \AB{Î”}.

\AgdaHide{
\begin{code}
infix 5 _âŠ†_
\end{code}}
\begin{code}
_âŠ†_ : (Î“ Î” : Con) â†’ Set
Î“ âŠ† Î” = Î” [ flip _âˆˆ_ ] Î“
\end{code}

Context inclusions allow for the formulation of weakening principles
explaining how to transport properties along inclusions. By a ``weakening
principle'', we mean that knowing that \AB{P} holds of \AB{Î“} and that
\AB{Î“} \AF{âŠ†} \AB{Î”} lets us conclude that \AB{P} holds for \AB{Î”} too.
In the case of variables, weakening merely corresponds to applying the
transport function in order to obtain a renamed variable. The case of
environments is also quite simple: being a pointwise lifting of a
relation \AB{R} between contexts and types, they enjoy weakening if
\AB{R} does.

\begin{code}
wk^âˆˆ : {Î” Î“ : Con} {Ïƒ : ty} (inc : Î“ âŠ† Î”) (pr : Ïƒ âˆˆ Î“) â†’ Ïƒ âˆˆ Î”
wk^âˆˆ inc pr = inc _ pr

wk[_] :  {â„“ : Level} {Î” : Con} {R : (Î” : Con) (Ïƒ : ty) â†’ Set â„“} (wk : {Î˜ : Con} {Ïƒ : ty} (inc : Î” âŠ† Î˜) â†’ R Î” Ïƒ â†’ R Î˜ Ïƒ)
         {Î“ Î˜ : Con} (inc : Î” âŠ† Î˜) (Ï : Î” [ R ] Î“) â†’  Î˜ [ R ] Î“
wk[ wk ] inc Ï = Î» Ïƒ pr â†’ wk inc $ Ï Ïƒ pr
\end{code}

These simple observations allow us to prove that context inclusions
form a preorder which, in turn, lets us provide the user with the
constructors Altenkirch, Hofmann and Streicher's ``Category of
Weakenings"~\cite{altenkirch1995categorical} is based on.

\begin{code}
refl : {Î“ : Con} â†’ Î“ âŠ† Î“
refl = Î» _ â†’ id

trans : {Î“ Î” Î˜ : Con} (incâ‚ : Î“ âŠ† Î”) (incâ‚‚ : Î” âŠ† Î˜) â†’ Î“ âŠ† Î˜
trans incâ‚ incâ‚‚ = wk[ wk^âˆˆ ] incâ‚‚ incâ‚

pop! : {Î” Î“ : Con} {Ïƒ : ty} (inc : Î“ âŠ† Î”) â†’ (Î“ âˆ™ Ïƒ) âŠ† (Î” âˆ™ Ïƒ)
pop! inc Ïƒ zero    = zero
pop! inc Ïƒ (1+ n)  = 1+ inc Ïƒ n

step : {Î” Î“ : Con} {Ïƒ : ty} (inc : Î“ âŠ† Î”) â†’ Î“ âŠ† (Î” âˆ™ Ïƒ)
step inc = trans inc $ Î» _ â†’ 1+_
\end{code}

Now that we are equipped with the notion of inclusion, we have all
the pieces necessary to describe the Kripke structure of our models
of the simply-typed Î»-calculus.

\section{Semantics and Generic Evaluation Functions}

The upcoming sections are dedicated to demonstrating that renaming,
substitution, printing with names, and normalisation by evaluation all
share the same structure. We start by abstracting away a notion of
\AR{Semantics} encompassing all these constructions. This approach
will make it possible for us to implement a generic traversal
parametrised by such a \AR{Semantics} once and for all and to focus
on the interesting model constructions instead of repeating the same
pattern over and over again.

A \AR{Semantics} is indexed by two relations \AB{ğ“”} and \AB{ğ“œ}
describing respectively the values in the environment and the ones
in the model. In cases such as substitution or normalisation by
evaluation, \AB{ğ“”} and \AB{ğ“œ} will happen to coincide but keeping
these two relations distinct is precisely what makes it possible
to go beyond these and also model renaming or printing with names.
The record packs the properties of these relations necessary to
define the evaluation function.

\begin{code}
record Semantics {â„“^E â„“^M : Level}
       (ğ“”  : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“^E)
       (ğ“œ  : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“^M) : Set (â„“^E âŠ” â„“^M) where
\end{code}
\AgdaHide{
\begin{code}
  infixl 5 _âŸ¦$âŸ§_
\end{code}}\vspace{-2.5em}%ugly but it works!
\begin{code}
  field
\end{code}

The first two methods of a \AR{Semantics} are dealing with environment
values. These values need to come with a notion of weakening (\ARF{wk})
so that the traversal may introduce fresh variables when going under a
binder and keep the environment well-scoped. We also need to be able to
manufacture environment values given a variable in scope (\ARF{embed})
in order to be able to craft a diagonal environment to evaluate an open
term.

\begin{code}
    wk      :  {Î“ Î” : Con} {Ïƒ : ty} (inc : Î“ âŠ† Î”) (r : ğ“” Î“ Ïƒ) â†’ ğ“” Î” Ïƒ
    embed   :  {Î“ : Con} (Ïƒ : ty) (pr : Ïƒ âˆˆ Î“) â†’ ğ“” Î“ Ïƒ
\end{code}

The structure of the model is quite constrained: each constructor
in the language needs a semantic counterpart. We start with the
two most interesting cases: \ARF{âŸ¦varâŸ§} and \ARF{âŸ¦Î»âŸ§}. The variable
case corresponds to the intuition that the environment attaches
interpretations to the variables in scope: it guarantees that one
can turn a value from the environment into a model one. The traversal
will therefore be able to, when hitting a variable, lookup the
corresponding value in the environment and return it.

\begin{code}
    âŸ¦varâŸ§   :  {Î“ : Con} {Ïƒ : ty} (v : ğ“” Î“ Ïƒ) â†’ ğ“œ Î“ Ïƒ
\end{code}

The semantic Î»-abstraction is notable for two reasons: first, following
Mitchell and Moggi~\cite{mitchell1991kripke}, it has a structure typical
of Kripke style models thus allowing arbitrary extensions of the context;
and second, instead of being a function in the host language taking values
in the model as arguments, it is a function that takes \emph{environment}
values. Indeed, the body of a Î»-abstraction exposes one extra free variable
thus prompting us to extend the evaluation environment with an additional
value. This slight variation in the type of semantic Î»-abstraction is what
guarantees that such an argument will be provided to us.

\begin{code}
    âŸ¦Î»âŸ§     :  {Î“ : Con} {Ïƒ Ï„ : ty} (t : {Î” : Con} (pr : Î“ âŠ† Î”) (u : ğ“” Î” Ïƒ) â†’ ğ“œ Î” Ï„) â†’ ğ“œ Î“ (Ïƒ `â†’ Ï„)
\end{code}

The remaining fields' types are a direct translation of the types
of the constructor they correspond to where the type constructor
characterising typing derivations (\AD{\_âŠ¢\_}) has been replaced
with the one corresponding to model values (\AB{ğ“œ}).

\begin{code}
    _âŸ¦$âŸ§_   :  {Î“ : Con} {Ïƒ Ï„ : ty} â†’ ğ“œ Î“ (Ïƒ `â†’ Ï„) â†’ ğ“œ Î“ Ïƒ â†’ ğ“œ Î“ Ï„
    âŸ¦âŸ¨âŸ©âŸ§    :  {Î“ : Con} â†’ ğ“œ Î“ `Unit
    âŸ¦ttâŸ§    :  {Î“ : Con} â†’ ğ“œ Î“ `Bool
    âŸ¦ffâŸ§    :  {Î“ : Con} â†’ ğ“œ Î“ `Bool
    âŸ¦ifteâŸ§  :  {Î“ : Con} {Ïƒ : ty} (b : ğ“œ Î“ `Bool) (l r : ğ“œ Î“ Ïƒ) â†’ ğ“œ Î“ Ïƒ
\end{code}

The fundamental lemma of semantics is then proven in a module indexed by
a \AF{Semantics}. It is defined by structural recursion on the term. Each
constructor is replaced by its semantic counterpart in order to combine the
induction hypotheses for its subterms. In the Î»-abstraction case, the type
of \ARF{âŸ¦Î»âŸ§} guarantees, in a fashion reminiscent of Normalisation by Evaluation,
that the semantic argument can be stored in the environment which will have
been weakened beforehand.

\begin{code}
module Eval {â„“^E â„“^M : Level} {ğ“” : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“^E} {ğ“œ : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“^M} (Sem : Semantics ğ“” ğ“œ) where
  open Semantics Sem
\end{code}\vspace{-2.5em}%ugly but it works!
\AgdaHide{
\begin{code}
  infix 10 _âŠ¨âŸ¦_âŸ§_ _âŠ¨eval_
\end{code}}
\begin{code}
  lemma : {Î” Î“ : Con} {Ïƒ : ty} (t : Î“ âŠ¢ Ïƒ) (Ï : Î” [ ğ“” ] Î“) â†’ ğ“œ Î” Ïƒ
  lemma (`var v)       Ï = âŸ¦varâŸ§ $ Ï _ v
  lemma (t `$ u)       Ï = lemma t Ï âŸ¦$âŸ§ lemma u Ï
  lemma (`Î» t)         Ï = âŸ¦Î»âŸ§  Î» inc u â†’ lemma t $ [ ğ“” ] wk[ wk ] inc Ï `âˆ™ u
  lemma `âŸ¨âŸ©            Ï = âŸ¦âŸ¨âŸ©âŸ§
  lemma `tt            Ï = âŸ¦ttâŸ§
  lemma `ff            Ï = âŸ¦ffâŸ§
  lemma (`ifte b l r)  Ï = âŸ¦ifteâŸ§ (lemma b Ï) (lemma l Ï) (lemma r Ï)
\end{code}

We introduce \AF{\_âŠ¨âŸ¦\_âŸ§\_} as an alternative name for the fundamental
lemma and \AF{\_âŠ¨eval\_} for the special case where we use \ARF{embed}
to generate a diagonal environment of type \AB{Î“} \AF{[} \AB{ğ“”} \AF{]}
\AB{Î“}. Because we open the module \AM{Eval} without passing it a parameter
of type \AF{Semantics}, the types of its elements are all Î»-lifted to include
an extra argument of such a type. This means that partial application of
\AF{\_âŠ¨âŸ¦\_âŸ§\_} will correspond to the specialisation of the fundamental
lemma to a given semantics. \AB{ğ“¢} \AF{âŠ¨âŸ¦} \AB{t} \AF{âŸ§} \AB{Ï} is
meant to convey the idea that the semantics \AB{ğ“¢} is used to evaluate
the term \AB{t} in the environment \AB{Ï}. Similarly, \AB{ğ“¢} \AF{âŠ¨eval}
\AB{t} is meant to denote the evaluation of the term \AB{t} in the semantics
\AB{ğ“¢} (using a diagonal environment).

\begin{code}
  _âŠ¨âŸ¦_âŸ§_ : {Î” Î“ : Con} {Ïƒ : ty} (t : Î“ âŠ¢ Ïƒ) (Ï : Î” [ ğ“” ] Î“) â†’ ğ“œ Î” Ïƒ
  _âŠ¨âŸ¦_âŸ§_ = lemma

  _âŠ¨eval_ : {Î“ : Con} {Ïƒ : ty} (t : Î“ âŠ¢ Ïƒ) â†’ ğ“œ Î“ Ïƒ
  _âŠ¨eval_ t = _âŠ¨âŸ¦_âŸ§_ t embed

open Eval hiding (lemma) public
\end{code}

The diagonal environment generated using \ARF{embed} when defining the
\AF{\_âŠ¨eval\_} function lets us kickstart the evaluation of arbitrary
\emph{open} terms. In the case of printing with names, this corresponds to
picking a naming scheme for free variables whilst in the usual model
construction used to perform normalisation by evaluation, it corresponds
to Î·-expanding the variables.

\section{Syntax is the Identity Semantics}

As we have explained earlier, this work has been directly influenced by
McBride's functional pearl~\cite{mcbride2005type}. It seems appropriate
to start our exploration of \AR{Semantics} with the two operations he
implements as a single traversal. We call these operations syntactic
because the values in the model are actual terms and almost all term
constructors are kept as their own semantic counterpart. As observed by
McBride, it is enough to provide three operations describing the properties
of the values in the environment to get a full-blown \AR{Semantics}. This
fact is witnessed by our simple \AR{Syntactic} record type together with
the \AF{syntactic} function turning its inhabitants into associated
\AR{Semantics}.

\begin{code}
record Syntactic {â„“ : Level} (ğ“” : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“) : Set â„“ where
  field
    embed  : {Î“ : Con} (Ïƒ : ty) (pr : Ïƒ âˆˆ Î“) â†’ ğ“” Î“ Ïƒ
    wk     : {Î“ Î” : Con} {Ïƒ : ty} (inc : Î“ âŠ† Î”) â†’ ğ“” Î“ Ïƒ â†’ ğ“” Î” Ïƒ
    âŸ¦varâŸ§  : {Î“ : Con} {Ïƒ : ty} (v : ğ“” Î“ Ïƒ) â†’ Î“ âŠ¢ Ïƒ

syntactic : {â„“ : Level} {ğ“” : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“} (syn : Syntactic ğ“”) â†’ Semantics ğ“” _âŠ¢_
syntactic syn = let open Syntactic syn in record
  { wk      = wk
  ; embed   = embed
  ; âŸ¦varâŸ§   = âŸ¦varâŸ§
  ; _âŸ¦$âŸ§_   = _`$_
  ; âŸ¦Î»âŸ§     = Î» t â†’ `Î» $ t (step refl) $ embed _ zero
  ; âŸ¦âŸ¨âŸ©âŸ§    = `âŸ¨âŸ©
  ; âŸ¦ttâŸ§    = `tt
  ; âŸ¦ffâŸ§    = `ff
  ; âŸ¦ifteâŸ§  = `ifte }
\end{code}

The shape of \ARF{âŸ¦Î»âŸ§} or \ARF{âŸ¦âŸ¨âŸ©âŸ§} should not trick the reader
into thinking that this definition performs some sort of Î·-expansion:
\AF{lemma} indeed only ever uses one of these when the evaluated term's
head constructor is already respectively a \AIC{`Î»} or a \AIC{`âŸ¨âŸ©}.
It is therefore absolutely possible to define renaming or substitution
using this approach. We can now port McBride's definitions to our
framework.

\subsubsection{Functoriality, also known as Renaming}

Our first example of a \AR{Syntactic} operation works with variables as
environment values. As a consequence, embedding is trivial; we have already
defined weakening earlier (see Section \ref{preorder}) and we can turn
a variable into a term by using the \AIC{`var} constructor.

\begin{code}
syntacticRenaming : Syntactic (flip _âˆˆ_)
syntacticRenaming =
  record  { embed  = Î» _ â†’ id
          ; wk     = wk^âˆˆ
          ; âŸ¦varâŸ§  = `var }

Renaming : Semantics (flip _âˆˆ_) _âŠ¢_
Renaming = syntactic syntacticRenaming
\end{code}

We obtain a rather involved definition of the identity of type \AB{Î“}
\AD{âŠ¢} \AB{Ïƒ} \AS{â†’} \AB{Î“} \AD{âŠ¢} \AB{Ïƒ} as \AF{Renaming} \AF{âŠ¨eval\_}.
But this construction is not at all useless: indeed, the more general
\AF{Renaming} \AF{âŠ¨âŸ¦\_âŸ§\_} function has type \AB{Î“} \AD{âŠ¢} \AB{Ïƒ} \AS{â†’}
\AB{Î“} \AF{âŠ†} \AB{Î”} \AS{â†’} \AB{Î”} \AD{âŠ¢} \AB{Ïƒ} which turns out to be
precisely the notion of weakening for terms we need once its arguments
have been flipped.

\begin{code}
wk^âŠ¢ : {Î” Î“ : Con} {Ïƒ : ty} (inc : Î“ âŠ† Î”) (t : Î“ âŠ¢ Ïƒ) â†’ Î” âŠ¢ Ïƒ
wk^âŠ¢ = flip $ Renaming âŠ¨âŸ¦_âŸ§_
\end{code}

\subsubsection{Simultaneous Substitution}

Our second example of a semantics is another spin on the syntactic model:
the environment values are now terms. We can embed variables into environment
values by using the \AIC{`var} constructor and we inherit weakening for terms
from the previous example.

\begin{code}
syntacticSubstitution : Syntactic _âŠ¢_
syntacticSubstitution =
  record  { embed   = Î» _ â†’ `var
          ; wk      = wk^âŠ¢
          ; âŸ¦varâŸ§   = id
          }

Substitution : Semantics _âŠ¢_ _âŠ¢_
Substitution = syntactic syntacticSubstitution
\end{code}

Because the diagonal environment used by \AF{Substitution} \AF{âŠ¨eval\_}
is obtained by \ARF{embed}ding membership proofs into terms using the
\AIC{`var} constructor, we get yet another definition of the identity
function on terms. The semantic function \AF{Substitution} \AF{âŠ¨âŸ¦\_âŸ§\_}
is again more interesting: it is an implementation of parallel substitution.

\begin{code}
subst : {Î“ Î” : Con} {Ïƒ : ty} (t : Î“ âŠ¢ Ïƒ) (Ï : Î” [ _âŠ¢_ ] Î“) â†’ Î” âŠ¢ Ïƒ
subst = Substitution âŠ¨âŸ¦_âŸ§_
\end{code}

\section{Printing with Names}
\label{prettyprint}

Before considering the various model constructions involved in defining
normalisation functions deciding different equational theories, let us
make a detour to a perhaps slightly more surprising example of a
\AF{Semantics}: Printing with Names. This example is quite interesting for
two reasons: it is another instance of a \AR{Semantics} where values in
the environment and values in the model have a different type, and for
the first time in this paper, the values in the model are monadic. A
user-facing project would naturally avoid directly building a \AD{String}
and rather construct an inhabitant of a more sophisticated datatype in order
to generate a prettier output~\cite{hughes1995design,wadler2003prettier}.
We stick to the simpler setup as pretty printing is not our focus here.

Firstly, the distinction between the type of values in the environment and
the ones in the model is once more instrumental in giving the procedure a
precise type guiding our implementation. Indeed, the environment carries
\emph{names} for the variables currently in scope whilst the inhabitants of
the model are \emph{computations} threading a stream to be used as a source
of fresh names every time a new variable is introduced by a Î»-abstraction.

\AgdaHide{
\begin{code}
open import Data.Char using (Char)
open import Data.String hiding (show)
open import Data.Nat.Show
open import Data.List as List hiding (_++_ ; zipWith ; [_])
open import Coinduction
open import Data.Stream as Stream using (Stream ; head ; tail ; zipWith ; _âˆ·_)
open import Category.Monad
open import Category.Monad.State
open RawIMonadState (StateMonadState (Stream String)) hiding (zipWith ; pure)
open import Relation.Binary.PropositionalEquality as PEq using (_â‰¡_)
\end{code}
}

\begin{code}
record Name (Î“ : Con) (Ïƒ : ty) : Set where
  constructor mkName
  field runName : String

record Printer (Î“ : Con) (Ïƒ : ty) : Set where
  constructor mkPrinter
  field runPrinter : State (Stream String) String
\end{code}
\AgdaHide{
\begin{code}
open Name
open Printer
\end{code}}

If the values in the environment were allowed to be computations too, we
would not root out all faulty implementations: the typechecker would for
instance quite happily accept a program picking a new name every time a
variable appears in the term.

Secondly, the fact that values in the model are computations and that this
poses no problem whatsoever in this framework means it is appropriate for
handling languages with effects~\cite{moggi1991notions}, or effectful
semantics (e.g. logging the various function calls).

\begin{code}
Printing : Semantics Name Printer
Printing = record
  { embed   = Î» _ â†’ mkName âˆ˜ show âˆ˜ deBruijn
  ; wk      = Î» _ â†’ mkName âˆ˜ runName
  ; âŸ¦varâŸ§   = mkPrinter âˆ˜ return âˆ˜ runName
  ; _âŸ¦$âŸ§_   =  Î» mf mt â†’ mkPrinter $ runPrinter mf >>= Î» `f` â†’
               runPrinter mt >>= Î» `t` â†’ return $ `f` ++ " (" ++ `t` ++ ")"
  ; âŸ¦Î»âŸ§     =  Î» {_} {Ïƒ} mb â†’ mkPrinter $ get >>= Î» names â†’ let `x` = head names in
               put (tail names)                                  >>= Î» _ â†’
               runPrinter (mb (step {Ïƒ = Ïƒ} refl) (mkName `x`))  >>= Î» `b` â†’
               return $ "Î»" ++ `x` ++ ". " ++ `b`
  ; âŸ¦âŸ¨âŸ©âŸ§    = mkPrinter $ return "âŸ¨âŸ©"
  ; âŸ¦ttâŸ§    = mkPrinter $ return "tt"
  ; âŸ¦ffâŸ§    = mkPrinter $ return "ff"
  ; âŸ¦ifteâŸ§  =  Î» mb ml mr â†’ mkPrinter $ runPrinter mb >>= Î» `b` â†’
               runPrinter ml >>= Î» `l` â†’ runPrinter mr >>= Î» `r` â†’
               return $ "if (" ++ `b`  ++ ") then (" ++ `l`
                                       ++ ") else (" ++ `r` ++ ")" }
\end{code}

Our definition of \ARF{embed} erases the membership proofs to
recover the corresponding de Bruijn indices which are then turned
into strings using \AF{show}, defined in Agda's standard library.
This means that, using \AF{Printing} \AF{âŠ¨eval\_}, the free
variables will be displayed as numbers whilst the bound ones will
be given names taken from the name supply. This is quite clearly
a rather crude name generation strategy and our approach to naming
would naturally be more sophisticated in a user-facing language.
We can for instance imagine that the binders arising from a user
input would carry naming hints based on the name the user picked
and that binders manufactured by the machine would be following
a type-based scheme: functions would be \AB{f}s or \AB{g}s, natural
numbers \AB{m}s, \AB{n}s, etc.

\begin{code}
  where
    deBruijn : {Î“ : Con} {Ïƒ : ty} â†’ Ïƒ âˆˆ Î“ â†’ â„•
    deBruijn zero    = 0
    deBruijn (1+ n)  = 1 + deBruijn n
\end{code}

Now, this means that we still need to provide a \AD{Stream} of fresh
names to this computation in order to run it. Given that \ARF{embed} erases
free variables to numbers, we'd rather avoid using numbers if we want to
avoid capture. We define \AF{names} (not shown here) as the stream
cycling through the letters of the alphabet and keeping the identifiers
unique by appending a natural number incremented by 1 each time we are
back to the beginning of the cycle.

\AgdaHide{
\begin{code}
flatten : {A : Set} â†’ Stream (A Ã— List A) â†’ Stream A
flatten ((a , as) âˆ· aass) = go a as (â™­ aass) where
  go : {A : Set} â†’ A â†’ List A â†’ Stream (A Ã— List A) â†’ Stream A
  go a []        aass = a âˆ· â™¯ flatten aass
  go a (b âˆ· as)  aass = a âˆ· â™¯ go b as aass
names : Stream String
names = flatten $ zipWith cons letters $ "" âˆ· â™¯ Stream.map show (allNatsFrom 0)
  where
    cons : (Char Ã— List Char) â†’ String â†’ (String Ã— List String)
    cons (c , cs) suffix = appendSuffix c , map appendSuffix cs where
      appendSuffix : Char â†’ String
      appendSuffix c  = fromList (c âˆ· []) ++ suffix

    letters = Stream.repeat $ 'a' , toList "bcdefghijklmnopqrstuvwxyz"

    allNatsFrom : â„• â†’ Stream â„•
    allNatsFrom k = k âˆ· â™¯ allNatsFrom (1 + k)
\end{code}}

Before defining \AF{print}, we introduce \AF{nameContext} (implementation
omitted here) which is a function delivering a stateful computation using
the provided stream of fresh names to generate an environment of names
for a given context. This means that we are now able to define a printing
function using names rather than number for the variables appearing free
in a term.

\begin{code}
nameContext : (Î” : Con) (Î“ : Con) â†’ State (Stream String) (Î” [ Name ] Î“)
\end{code}
\AgdaHide{
\begin{code}
nameContext Î” Îµ        =  return $ Î» _ ()
nameContext Î” (Î“ âˆ™ Ïƒ)  =  nameContext Î” Î“ >>= Î» g â†’
                        get >>= Î» names â†’ put (tail names) >>
                        return ([ Name ] g `âˆ™ mkName (head names))
\end{code}}\vspace{-2em}%ugly but it works!
\begin{code}
print : {Î“ : Con} {Ïƒ : ty} (t : Î“ âŠ¢ Ïƒ) â†’ String
print {Î“} t = projâ‚ $ (nameContext Î“ Î“ >>= runPrinter âˆ˜ Printing âŠ¨âŸ¦ t âŸ§_) names
\end{code}

We can observe that \AF{print} does indeed do the job by writing a
test. Given that type theory allows computation at the type level, we can
make sure that such tests are checked at typechecking time. Here we display
a function applying its argument to the first free variable in scope. The
free variable is indeed given a natural number as a name whilst the bound
one uses a letter.

\begin{code}
pretty$ : {a b : ty} â†’ print {Î“ = Îµ âˆ™ a `â†’ b} (`Î» $ `var (1+ zero) `$ `var zero) â‰¡ "Î»b. a (b)"
pretty$ = PEq.refl
\end{code}

\section{Normalisation by Evaluation}

Normalisation by Evaluation is a technique exploiting the computational
power of a host language in order to normalise expressions of a deeply
embedded one. The process is based on a model construction associating
a type of values \model{} to each context \AB{Î“} and type \AB{Ïƒ}. Two
procedures are then defined: the first one (\AF{eval}) produces elements
of \model{} provided a well-typed term of the corresponding \AB{Î“} \AD{âŠ¢}
\AB{Ïƒ} type and an interpretation for the variables in \AB{Î“} whilst
the second one (\AF{reify}) extracts, in a type-directed manner, normal
forms \AB{Î“} \AD{âŠ¢^{nf}} \AB{Ïƒ} from elements of the model \model{}.
Normalisation is achieved by composing the two procedures.

The definition of this \AF{eval} function is a natural candidate for our
\AF{Semantics} framework. Normalisation is always defined for a given
equational theory so we are going to start by recalling the various
rules a theory may satisfy.

\paragraph{Î²-rule} Using the \AF{Substitution} \AF{Semantics}, we can
describe Î²-reduction in the usual manner.

\begin{mathpar}
\inferrule{
  }{\text{(\AIC{`Î»} \AB{t}) \AIC{`\$} \AB{u} â† \AB{t} \AF{âŸ¨} \AB{u} \AF{/varâ‚€âŸ©}}
  }{Î²}
\end{mathpar}
\AgdaHide{
\begin{code}
infixl 10 _âŸ¨_/varâ‚€âŸ©
\end{code}}
\begin{code}
_âŸ¨_/varâ‚€âŸ© : {Î“ : Con} {Ïƒ Ï„ : ty} (t : Î“ âˆ™ Ïƒ âŠ¢ Ï„) (u : Î“ âŠ¢ Ïƒ) â†’ Î“ âŠ¢ Ï„
t âŸ¨ u /varâ‚€âŸ© = subst t $ [ _âŠ¢_ ] (Î» _ â†’ `var) `âˆ™ u
\end{code}

\paragraph{Î¹-rule} The presence of an inductive data type (\AIC{`Bool})
and its eliminator (\AIC{`ifte}) means we have an extra opportunity for
computations to happen when the boolean the eliminator is branching
over is in canonical form.

\begin{mathpar}
\inferrule{
  }{\text{\AIC{`ifte} \AIC{`tt} \AB{l} \AB{r} â† \AB{l}}
  }{Î¹_1}
\and
\inferrule{
  }{\text{\AIC{`ifte} \AIC{`ff} \AB{l} \AB{r} â† \AB{r}}
  }{Î¹_2}
\end{mathpar}

\paragraph{Î¾-rule} The Î¾-rule is what makes the distinction between
strong normalisation and weak head normalisation. It allows reductions
to take place under lambdas.

\begin{mathpar}
\inferrule{\text{\AB{t} â† \AB{u}}
  }{\text{\AIC{`Î»} \AB{t} â† \AIC{`Î»} \AB{u}}
  }{Î¾}
\end{mathpar}

\paragraph{Î·-rule} Finally the Î·-rules are saying that for some types,
terms have a canonical form: functions will all be Î»-headed whilst
record will be a collection of fields which translates here to all
the elements of the \AIC{`Unit} type being equal to \AIC{`âŸ¨âŸ©}.

\begin{mathpar}
\inferrule{
  }{\text{\AB{t} â† \AF{eta} \AB{t}}
  }{Î·_1}
\and
\inferrule{\text{\AB{t} \AgdaSymbol{:} \AB{Î“} \AD{âŠ¢} \AIC{`Unit}}
  }{\text{\AB{t} â† \AIC{`âŸ¨âŸ©}}
  }{Î·_2}
\end{mathpar}
\begin{code}
eta : {Î“ : Con} {Ïƒ Ï„ : ty} (t : Î“ âŠ¢ Ïƒ `â†’ Ï„) â†’ Î“ âŠ¢ Ïƒ `â†’ Ï„
eta t = `Î» $ wk^âŠ¢ (step refl) t `$ `var zero
\end{code}

Now that we have recalled all these rules, we can talk precisely
about the sort of equational theory decided by the model construction
we choose to perform. We start with the usual definition of Normalisation
by Evaluation which goes under Î»s and produces Î·-long Î²Î¹-short normal
forms.

\subsection{Normalisation by Evaluation for Î²Î¹Î¾Î·}
\label{nbe}

In the case of Normalisation by Evaluation, the elements of the model
and the ones carried by the environment will both have the same type:
\AF{\_âŠ¨^{Î²Î¹Î¾Î·}\_}, defined by induction on its second argument. In
order to formally describe this construction, we need to have a precise
notion of normal forms. Indeed if the Î·-rules guarantee that we can
represent functions (respectively inhabitants of \AIC{`Unit}) in the
source language as function spaces (respectively \AR{âŠ¤}) in Agda, there
are no such rules for \AIC{`Bool}ean values which will be represented
as normal forms of the right type i.e. as either \AIC{`tt}, \AIC{`ff}
or a neutral expression.

These normal forms can be formally described by two mutually defined
inductive families: \AD{\_âŠ¢[\_]^{ne}\_} is the type of stuck terms made
up of a variable to which a spine of eliminators in normal forms is
applied; and \AD{\_âŠ¢[\_]^{nf}\_} describes the normal forms. These
families are parametrised by a predicate \AB{R} characterising the
types at which the user is allowed to turn a neutral expression into a
normal form as demonstrated by the constructor \AIC{`embed}'s first argument.

\AgdaHide{
\begin{code}
infix 5 _âŠ¢[_]^ne_ _âŠ¢[_]^nf_
mutual
\end{code}}
\begin{code}
  data _âŠ¢[_]^ne_ (Î“ : Con) (R : ty â†’ Set) (Ïƒ : ty) : Set where
    `var   : (v : Ïƒ âˆˆ Î“) â†’ Î“ âŠ¢[ R ]^ne Ïƒ
    _`$_   : {Ï„ : ty} (t : Î“ âŠ¢[ R ]^ne Ï„ `â†’ Ïƒ) (u : Î“ âŠ¢[ R ]^nf Ï„) â†’ Î“ âŠ¢[ R ]^ne Ïƒ
    `ifte  : (b : Î“ âŠ¢[ R ]^ne `Bool) (l r : Î“ âŠ¢[ R ]^nf Ïƒ) â†’ Î“ âŠ¢[ R ]^ne Ïƒ

  data _âŠ¢[_]^nf_ (Î“ : Con) (R : ty â†’ Set) : (Ïƒ : ty) â†’ Set where
    `embed  : {Ïƒ : ty} (pr : R Ïƒ) (t : Î“ âŠ¢[ R ]^ne Ïƒ) â†’ Î“ âŠ¢[ R ]^nf Ïƒ
    `âŸ¨âŸ©     : Î“ âŠ¢[ R ]^nf `Unit
    `tt     : Î“ âŠ¢[ R ]^nf `Bool
    `ff     : Î“ âŠ¢[ R ]^nf `Bool
    `Î»      : {Ïƒ Ï„ : ty} (b : Î“ âˆ™ Ïƒ âŠ¢[ R ]^nf Ï„) â†’ Î“ âŠ¢[ R ]^nf (Ïƒ `â†’ Ï„)
\end{code}

Once more, context inclusions induce a notion of weakening. We hide
the purely structural definition of \AF{wk^{ne}} and \AF{wk^{nf}}
but quickly recall their respective types:

\begin{code}
wk^ne : {Î” Î“ : Con} (inc : Î“ âŠ† Î”) {R : ty â†’ Set} {Ïƒ : ty} (ne : Î“ âŠ¢[ R ]^ne Ïƒ) â†’ Î” âŠ¢[ R ]^ne Ïƒ
wk^nf : {Î” Î“ : Con} (inc : Î“ âŠ† Î”) {R : ty â†’ Set} {Ïƒ : ty} (ne : Î“ âŠ¢[ R ]^nf Ïƒ) â†’ Î” âŠ¢[ R ]^nf Ïƒ
\end{code}
\AgdaHide{
\begin{code}
wk^ne inc (`var v)        = `var $â€² wk^âˆˆ inc v
wk^ne inc (ne `$ u)       = wk^ne inc ne `$ wk^nf inc u
wk^ne inc (`ifte ne l r)  = `ifte (wk^ne inc ne) (wk^nf inc l) (wk^nf inc r)

wk^nf inc (`embed pr t) = `embed pr $â€² wk^ne inc t
wk^nf inc `âŸ¨âŸ©           = `âŸ¨âŸ©
wk^nf inc `tt           = `tt
wk^nf inc `ff           = `ff
wk^nf inc (`Î» nf)       = `Î» $â€² wk^nf (pop! inc) nf

infix 5 [_,_]
[_,_] : {Î“ : Con} {Ï„ : ty} {P : (Ïƒ : ty) (pr : Ïƒ âˆˆ Î“ âˆ™ Ï„) â†’ Set} â†’
        (p0 : P Ï„ zero) â†’
        (pS : (Ïƒ : ty) (n : Ïƒ âˆˆ Î“) â†’ P Ïƒ (1+ n)) â†’
        (Ïƒ : ty) (pr : Ïƒ âˆˆ Î“ âˆ™ Ï„) â†’ P Ïƒ pr
[ p0 , pS ] Ïƒ zero    = p0
[ p0 , pS ] Ïƒ (1+ n)  = pS Ïƒ n

mutual

  wk^nf-reflâ€² : {Î“ : Con} {R : ty â†’ Set} {Ïƒ : ty} {f : Î“ âŠ† Î“} (prf : (Ïƒ : ty) (pr : Ïƒ âˆˆ Î“) â†’ f Ïƒ pr â‰¡ pr) â†’
                (t : Î“ âŠ¢[ R ]^nf Ïƒ) â†’ wk^nf f t â‰¡ t
  wk^nf-reflâ€² prf (`embed pr t)  = PEq.cong (`embed pr) $ wk^ne-reflâ€² prf t
  wk^nf-reflâ€² prf `âŸ¨âŸ©            = PEq.refl
  wk^nf-reflâ€² prf `tt            = PEq.refl
  wk^nf-reflâ€² prf `ff            = PEq.refl
  wk^nf-reflâ€² prf (`Î» t)         = PEq.cong `Î» $ wk^nf-reflâ€² ([ PEq.refl , (Î» Ïƒ â†’ PEq.cong 1+_ âˆ˜ prf Ïƒ) ]) t

  wk^ne-reflâ€² : {Î“ : Con} {R : ty â†’ Set} {Ïƒ : ty} {f : Î“ âŠ† Î“} (prf : (Ïƒ : ty) (pr : Ïƒ âˆˆ Î“) â†’ f Ïƒ pr â‰¡ pr) â†’
                (t : Î“ âŠ¢[ R ]^ne Ïƒ) â†’ wk^ne f t â‰¡ t
  wk^ne-reflâ€² prf (`var v)       = PEq.cong `var $ prf _ v
  wk^ne-reflâ€² prf (t `$ u)       = PEq.congâ‚‚ _`$_ (wk^ne-reflâ€² prf t) (wk^nf-reflâ€² prf u)
  wk^ne-reflâ€² prf (`ifte b l r)  = PEq.congâ‚‚ (uncurry `ifte) (PEq.congâ‚‚ _,_ (wk^ne-reflâ€² prf b) (wk^nf-reflâ€² prf l)) (wk^nf-reflâ€² prf r)

mutual

  wk^nf-transâ€² : {Î˜ Î” Î“ : Con} {R : ty â†’ Set} {Ïƒ : ty} {incâ‚ : Î“ âŠ† Î”} {incâ‚‚ : Î” âŠ† Î˜}
                 {f : Î“ âŠ† Î˜} (prf : (Ïƒ : ty) (pr : Ïƒ âˆˆ Î“) â†’ trans incâ‚ incâ‚‚ Ïƒ pr â‰¡ f Ïƒ pr)
                 (t : Î“ âŠ¢[ R ]^nf Ïƒ) â†’  wk^nf incâ‚‚ (wk^nf incâ‚ t) â‰¡ wk^nf f t
  wk^nf-transâ€² prf (`embed pr t)  = PEq.cong (`embed pr) (wk^ne-transâ€² prf t)
  wk^nf-transâ€² prf `âŸ¨âŸ©            = PEq.refl
  wk^nf-transâ€² prf `tt            = PEq.refl
  wk^nf-transâ€² prf `ff            = PEq.refl
  wk^nf-transâ€² prf (`Î» t)         = PEq.cong `Î» $ wk^nf-transâ€² ([ PEq.refl , (Î» Ïƒ â†’ PEq.cong 1+_ âˆ˜ prf Ïƒ) ]) t

  wk^ne-transâ€² : {Î˜ Î” Î“ : Con} {R : ty â†’ Set} {Ïƒ : ty} {incâ‚ : Î“ âŠ† Î”} {incâ‚‚ : Î” âŠ† Î˜}
                 {f : Î“ âŠ† Î˜} (prf : (Ïƒ : ty) (pr : Ïƒ âˆˆ Î“) â†’ trans incâ‚ incâ‚‚ Ïƒ pr â‰¡ f Ïƒ pr)
                 (t : Î“ âŠ¢[ R ]^ne Ïƒ) â†’  wk^ne incâ‚‚ (wk^ne incâ‚ t) â‰¡ wk^ne f t
  wk^ne-transâ€² prf (`var v)       = PEq.cong `var (prf _ v)
  wk^ne-transâ€² prf (t `$ u)       = PEq.congâ‚‚ _`$_ (wk^ne-transâ€² prf t) (wk^nf-transâ€² prf u)
  wk^ne-transâ€² prf (`ifte b l r)  = PEq.congâ‚‚ (uncurry `ifte) (PEq.congâ‚‚ _,_ (wk^ne-transâ€² prf b) (wk^nf-transâ€² prf l)) (wk^nf-transâ€² prf r)

wk^nf-refl : {Î“ : Con} {R : ty â†’ Set} {Ïƒ : ty} (t : Î“ âŠ¢[ R ]^nf Ïƒ) â†’ wk^nf refl t â‰¡ t
wk^nf-refl = wk^nf-reflâ€² (Î» _ _ â†’ PEq.refl)

wk^ne-refl : {Î“ : Con} {R : ty â†’ Set} {Ïƒ : ty} (t : Î“ âŠ¢[ R ]^ne Ïƒ) â†’ wk^ne refl t â‰¡ t
wk^ne-refl = wk^ne-reflâ€² (Î» _ _ â†’ PEq.refl)

wk^nf-trans : {Î˜ Î” Î“ : Con} {R : ty â†’ Set} {Ïƒ : ty} (incâ‚ : Î“ âŠ† Î”) (incâ‚‚ : Î” âŠ† Î˜)
               (t : Î“ âŠ¢[ R ]^nf Ïƒ) â†’  wk^nf incâ‚‚ (wk^nf incâ‚ t) â‰¡ wk^nf (trans incâ‚ incâ‚‚) t
wk^nf-trans incâ‚ incâ‚‚ = wk^nf-transâ€² (Î» _ _ â†’ PEq.refl)

wk^ne-trans : {Î˜ Î” Î“ : Con} {R : ty â†’ Set} {Ïƒ : ty} (incâ‚ : Î“ âŠ† Î”) (incâ‚‚ : Î” âŠ† Î˜)
               (t : Î“ âŠ¢[ R ]^ne Ïƒ) â†’  wk^ne incâ‚‚ (wk^ne incâ‚ t) â‰¡ wk^ne (trans incâ‚ incâ‚‚) t
wk^ne-trans incâ‚ incâ‚‚ = wk^ne-transâ€² (Î» _ _ â†’ PEq.refl)
\end{code}}

We now come to the definition of the model. In order to guarantee that
we use the Î·-rules eagerly, we introduce the predicate \AF{R^{Î²Î¹Î¾Î·}}
characterising the types for which we may turn a neutral expression into
a normal form. It is equivalent to \AR{âŠ¤} for \AIC{`Bool} (meaning that
the proof can be inferred by Agda by a simple Î·-expansion) and to \AD{âŠ¥}
for any other type. This effectively guarantees that all inhabitants of
\AB{Î“} \AF{âŠ¢[} \AF{R^{Î²Î¹Î¾Î·}} \AF{]^{nf}} \AIC{`Unit} are equal to \AIC{`âŸ¨âŸ©}
and that all inhabitants of \AB{Î“} \AF{âŠ¢[} \AF{R^{Î²Î¹Î¾Î·}} \AF{]^{nf}} (\AB{Ïƒ}
\AIC{`â†’} \AB{Ï„}) are \AIC{`Î»}-headed.

\begin{code}
R^Î²Î¹Î¾Î· : ty â†’ Set
R^Î²Î¹Î¾Î· `Bool  = âŠ¤
R^Î²Î¹Î¾Î· _      = âŠ¥
\end{code}

The model construction then follows the usual pattern pioneered by
Berger~\cite{berger1993program} and formally analysed and thoroughly
explained by Catarina Coquand~\cite{coquand2002formalised} in the case
of a simply-typed lambda calculus with explicit substitutions. We proceed by
induction on the type and make sure that Î·-expansion is applied eagerly: all
inhabitants of \AB{Î“} \AF{âŠ¨^Î²Î¹Î¾Î·} \AIC{`Unit} are indeed equal and all elements
of \AB{Î“} \AF{âŠ¨^Î²Î¹Î¾Î·} (\AB{Ïƒ} \AIC{`â†’} \AB{Ï„}) are functions in Agda meaning
that their reifications will be guaranteed to be \AIC{`Î»}-headed.

\AgdaHide{
\begin{code}
infix 5 _âŠ¨^Î²Î¹Î¾Î·_
\end{code}}
\begin{code}
_âŠ¨^Î²Î¹Î¾Î·_ : (Î“ : Con) (Ïƒ : ty) â†’ Set
Î“ âŠ¨^Î²Î¹Î¾Î· `Unit   = âŠ¤
Î“ âŠ¨^Î²Î¹Î¾Î· `Bool   = Î“ âŠ¢[ R^Î²Î¹Î¾Î· ]^nf `Bool
Î“ âŠ¨^Î²Î¹Î¾Î· Ïƒ `â†’ Ï„  = {Î” : Con} (inc : Î“ âŠ† Î”) (u : Î” âŠ¨^Î²Î¹Î¾Î· Ïƒ) â†’ Î” âŠ¨^Î²Î¹Î¾Î· Ï„
\end{code}

Normal forms may be weakened, and context inclusions may be composed hence
the rather simple definition of weakening for inhabitants of the model.

\begin{code}
wk^Î²Î¹Î¾Î· : {Î” Î“ : Con} (Ïƒ : ty) (inc : Î“ âŠ† Î”) (T : Î“ âŠ¨^Î²Î¹Î¾Î· Ïƒ) â†’ Î” âŠ¨^Î²Î¹Î¾Î· Ïƒ
wk^Î²Î¹Î¾Î· `Unit     inc T = T
wk^Î²Î¹Î¾Î· `Bool     inc T = wk^nf inc T
wk^Î²Î¹Î¾Î· (Ïƒ `â†’ Ï„)  inc T = Î» incâ€² â†’ T $â€² trans inc incâ€²
\end{code}

The semantic counterpart of application combines two elements of the model:
a functional part of type \AB{Î“} \AF{âŠ¨^{Î²Î¹Î¾Î·}} \AS{(}\AB{Ïƒ} \AIC{`â†’} \AB{Ï„}\AS{)}
and its argument of type \AB{Î“} \AF{âŠ¨^{Î²Î¹Î¾Î·}} \AB{Ïƒ} which can be fed to the
functional given a proof that \AB{Î“} \AF{âŠ†} \AB{Î“}. But we already have
proven that \AF{\_âŠ†\_} is a preorder (see Section ~\ref{preorder}) so this
is not at all an issue.

\AgdaHide{
\begin{code}
infixr 5 _$^Î²Î¹Î¾Î·_
\end{code}}
\begin{code}
_$^Î²Î¹Î¾Î·_ : {Î“ : Con} {Ïƒ Ï„ : ty} (t : Î“ âŠ¨^Î²Î¹Î¾Î· Ïƒ `â†’ Ï„) (u : Î“ âŠ¨^Î²Î¹Î¾Î· Ïƒ) â†’ Î“ âŠ¨^Î²Î¹Î¾Î· Ï„
t $^Î²Î¹Î¾Î· u = t refl u
\end{code}

Conditional Branching on the other hand is a bit more subtle: because the boolean
value \AIC{`ifte} is branching over may be a neutral term, we are forced to define
the reflection and reification mechanisms first. These functions, also known as
unquote and quote respectively, are showing the interplay between neutral terms,
model values and normal forms. \AF{reflect^{Î²Î¹Î¾Î·}} performs a form of semantical
Î·-expansion: all stuck \AIC{`Unit} terms are projected to the same element \AIC{tt},
and all stuck functions are turned into functions in the host language.

\begin{code}
mutual

  varâ€¿0^Î²Î¹Î¾Î· : {Î“ : Con} {Ïƒ : ty} â†’ Î“ âˆ™ Ïƒ âŠ¨^Î²Î¹Î¾Î· Ïƒ
  varâ€¿0^Î²Î¹Î¾Î· = reflect^Î²Î¹Î¾Î· _ $â€² `var zero

  reflect^Î²Î¹Î¾Î· : {Î“ : Con} (Ïƒ : ty) (t : Î“ âŠ¢[ R^Î²Î¹Î¾Î· ]^ne Ïƒ) â†’ Î“ âŠ¨^Î²Î¹Î¾Î· Ïƒ
  reflect^Î²Î¹Î¾Î· `Unit     t = âŸ¨âŸ©
  reflect^Î²Î¹Î¾Î· `Bool     t = `embed _ t
  reflect^Î²Î¹Î¾Î· (Ïƒ `â†’ Ï„)  t = Î» inc u â†’ reflect^Î²Î¹Î¾Î· Ï„ $â€² wk^ne inc t `$ reify^Î²Î¹Î¾Î· Ïƒ u

  reify^Î²Î¹Î¾Î· : {Î“ : Con} (Ïƒ : ty) (T : Î“ âŠ¨^Î²Î¹Î¾Î· Ïƒ) â†’ Î“ âŠ¢[ R^Î²Î¹Î¾Î· ]^nf Ïƒ
  reify^Î²Î¹Î¾Î· `Unit     T = `âŸ¨âŸ©
  reify^Î²Î¹Î¾Î· `Bool     T = T
  reify^Î²Î¹Î¾Î· (Ïƒ `â†’ Ï„)  T = `Î» $â€² reify^Î²Î¹Î¾Î· Ï„ $â€² T (step refl) varâ€¿0^Î²Î¹Î¾Î·
\end{code}

The semantic counterpart of \AIC{`ifte} can then be defined: if the boolean
is a value, the appropriate branch is picked and if it is stuck the whole
expression is reflected in the model.

\begin{code}
ifte^Î²Î¹Î¾Î· : {Î“ : Con} {Ïƒ : ty} (b : Î“ âŠ¨^Î²Î¹Î¾Î· `Bool) (l r : Î“ âŠ¨^Î²Î¹Î¾Î· Ïƒ) â†’ Î“ âŠ¨^Î²Î¹Î¾Î· Ïƒ
ifte^Î²Î¹Î¾Î· `tt           l r = l
ifte^Î²Î¹Î¾Î· `ff           l r = r
ifte^Î²Î¹Î¾Î· (`embed _ T)  l r = reflect^Î²Î¹Î¾Î· _ $â€² `ifte T (reify^Î²Î¹Î¾Î· _ l) (reify^Î²Î¹Î¾Î· _ r)
\end{code}

The \AF{Semantics} corresponding to Normalisation by Evaluation for Î²Î¹Î¾Î·-rules
uses \AF{\_âŠ¨^Î²Î¹Î¾Î·\_} for values in the environment as well as the ones in the
model. The semantic counterpart of a Î»-abstraction is simply the identity: the
structure of the functional case in the definition of the model matches precisely
the shape expected in a \AF{Semantics}. Because the environment carries model values,
the variable case simply returns the value it is given.

\begin{code}
Normalise^Î²Î¹Î¾Î· : Semantics _âŠ¨^Î²Î¹Î¾Î·_ _âŠ¨^Î²Î¹Î¾Î·_
Normalise^Î²Î¹Î¾Î· =
  record  { embed   = Î» Ïƒ â†’ reflect^Î²Î¹Î¾Î· Ïƒ âˆ˜ `var
          ; wk      = wk^Î²Î¹Î¾Î· _
          ; âŸ¦varâŸ§   = id
          ; _âŸ¦$âŸ§_   = _$^Î²Î¹Î¾Î·_
          ; âŸ¦Î»âŸ§     = id
          ; âŸ¦âŸ¨âŸ©âŸ§    = âŸ¨âŸ©
          ; âŸ¦ttâŸ§    = `tt
          ; âŸ¦ffâŸ§    = `ff
          ; âŸ¦ifteâŸ§  = ifte^Î²Î¹Î¾Î·
          }
\end{code}

The diagonal environment built up in \AF{Normalise^Î²Î¹Î¾Î·} \AF{âŠ¨eval\_}
consists of Î·-expanded variables. Normalisation is obtained by reifying
the result obtained by evaluation.

\begin{code}
norm^Î²Î¹Î¾Î· : {Î“ : Con} (Ïƒ : ty) (t : Î“ âŠ¢ Ïƒ) â†’ Î“ âŠ¢[ R^Î²Î¹Î¾Î· ]^nf Ïƒ
norm^Î²Î¹Î¾Î· Ïƒ t = reify^Î²Î¹Î¾Î· Ïƒ $â€² Normalise^Î²Î¹Î¾Î· âŠ¨eval t
\end{code}

\subsection{Normalisation by Evaluation for Î²Î¹Î¾}

As we have just seen, the traditional typed model construction leads to a
normalisation procedure outputting Î²Î¹-normal Î·-long terms. However evaluation
strategies implemented in actual proof systems tend to avoid applying Î·-rules
as much as possible: quite unsurprisingly, when typechecking complex developments
expanding the proof terms is a really bad idea. Garillot and colleagues~\cite{garillot2009packaging}
report that common mathematical structures packaged in records can lead to terms
of such a size that theorem proving becomes impractical.

In these systems, normal forms are neither Î·-long nor Î·-short: the Î·-rule is
actually never considered except when comparing two terms for equality, one of
which is neutral whilst the other is constructor-headed. Instead of declaring
them to be distinct, the algorithm will perform one step of Î·-expansion on the
neutral term and keep comparing their subterms structurally. The conversion test
will only fail when confronted with two neutral terms which have distinct head
variables or two normal forms with distinct head constructors.

To reproduce this behaviour, the normalisation procedure needs to be amended.
It is possible to alter the model definition described earlier so that it
avoids unnecessary Î·-expansions. We proceed by enriching the traditional
model with extra syntactical artefacts in a manner reminiscent of Coquand
and Dybjer's approach to defining a Normalisation by Evaluation procedure
for the SK combinator calculus~\cite{CoqDybSK}. Their resorting to glueing
terms to elements of the model was dictated by the sheer impossibily to write
a sensible reification procedure but, in hindsight, it provides us with a
powerful technique to build models internalizing alternative equational
theories. This leads us to mutually defining the model (\AF{\_âŠ¨^{Î²Î¹Î¾}\_})
together with the \emph{acting} model (\AF{\_âŠ¨^{Î²Î¹Î¾â‹†}\_}):

\begin{code}
R^Î²Î¹Î¾ : ty â†’ Set
R^Î²Î¹Î¾ _ = âŠ¤
\end{code}

\AgdaHide{
\begin{code}
infix 5 _âŠ¨^Î²Î¹Î¾_ _âŠ¨^Î²Î¹Î¾â‹†_
\end{code}}
\begin{code}
mutual

  _âŠ¨^Î²Î¹Î¾_   : (Î“ : Con) (Ïƒ : ty) â†’ Set
  Î“ âŠ¨^Î²Î¹Î¾ Ïƒ  = Î“ âŠ¢[ R^Î²Î¹Î¾ ]^ne Ïƒ âŠ Î“ âŠ¨^Î²Î¹Î¾â‹† Ïƒ

  _âŠ¨^Î²Î¹Î¾â‹†_  : (Î“ : Con) (Ïƒ : ty) â†’ Set
  Î“ âŠ¨^Î²Î¹Î¾â‹† `Unit   = âŠ¤
  Î“ âŠ¨^Î²Î¹Î¾â‹† `Bool   = Bool
  Î“ âŠ¨^Î²Î¹Î¾â‹† Ïƒ `â†’ Ï„  = {Î” : Con} (inc : Î“ âŠ† Î”) (u : Î” âŠ¨^Î²Î¹Î¾ Ïƒ) â†’ Î” âŠ¨^Î²Î¹Î¾ Ï„
\end{code}

These mutual definitions allow us to make a careful distinction between values
arising from (non expanded) stuck terms and the ones wich are constructor headed
and have a computational behaviour associated to them. The values in the acting
model are storing these behaviours be it either actual proofs of \AF{âŠ¤}, actual
\AF{Bool}eans or actual Agda functions depending on the type of the term. It is
important to note that the functions in the acting model have the model as both
domain and codomain: there is no reason to exclude the fact that both the argument
or the body may or may not be stuck.

The definition of weakening for these structures is rather straightforward
albeit slightly more complex than for the usual definition of Normalisation
by Evaluation seen in Section ~\ref{nbe}.

\begin{code}
wk^Î²Î¹Î¾â‹† : {Î” Î“ : Con} (inc : Î“ âŠ† Î”) {Ïƒ : ty} (T : Î“ âŠ¨^Î²Î¹Î¾â‹† Ïƒ) â†’ Î” âŠ¨^Î²Î¹Î¾â‹† Ïƒ
wk^Î²Î¹Î¾â‹† inc {`Unit   } T = T
wk^Î²Î¹Î¾â‹† inc {`Bool   } T = T
wk^Î²Î¹Î¾â‹† inc {Ïƒ `â†’ Ï„  } T = Î» incâ€² â†’ T $â€² trans inc incâ€²

wk^Î²Î¹Î¾ : {Î” Î“ : Con} {Ïƒ : ty} (inc : Î“ âŠ† Î”) (T : Î“ âŠ¨^Î²Î¹Î¾ Ïƒ) â†’ Î” âŠ¨^Î²Î¹Î¾ Ïƒ
wk^Î²Î¹Î¾ inc (injâ‚ ne)  = injâ‚ $ wk^ne inc ne
wk^Î²Î¹Î¾ inc (injâ‚‚ T)   = injâ‚‚ $ wk^Î²Î¹Î¾â‹† inc T
\end{code}

What used to be called reflection in the previous model is now trivial:
stuck terms are indeed perfectly valid model values. Reification becomes
quite straightforward too because no Î·-expansion is needed. When facing
a stuck term, we simply embed it in the set of normal forms. Even though
\AF{reify^{Î²Î¹Î¾â‹†}} may look like it is performing some Î·-expansions, it
is not the case: all the values in the acting model are notionally obtained
from constructor-headed terms.

\begin{code}
reflect^Î²Î¹Î¾ : {Î“ : Con} (Ïƒ : ty) (t : Î“ âŠ¢[ R^Î²Î¹Î¾ ]^ne Ïƒ) â†’ Î“ âŠ¨^Î²Î¹Î¾ Ïƒ
reflect^Î²Î¹Î¾ Ïƒ = injâ‚

mutual

  reify^Î²Î¹Î¾â‹† : {Î“ : Con} (Ïƒ : ty) (T : Î“ âŠ¨^Î²Î¹Î¾â‹† Ïƒ) â†’ Î“ âŠ¢[ R^Î²Î¹Î¾ ]^nf Ïƒ
  reify^Î²Î¹Î¾â‹† `Unit     T = `âŸ¨âŸ©
  reify^Î²Î¹Î¾â‹† `Bool     T = if T then `tt else `ff
  reify^Î²Î¹Î¾â‹† (Ïƒ `â†’ Ï„)  T = `Î» $â€² reify^Î²Î¹Î¾ Ï„ $â€² T (step refl) varâ€¿0^Î²Î¹Î¾
    where varâ€¿0^Î²Î¹Î¾ = injâ‚ $ `var zero

  reify^Î²Î¹Î¾ : {Î“ : Con} (Ïƒ : ty) (T : Î“ âŠ¨^Î²Î¹Î¾ Ïƒ) â†’ Î“ âŠ¢[ R^Î²Î¹Î¾ ]^nf Ïƒ
  reify^Î²Î¹Î¾ Ïƒ (injâ‚ ne)  = `embed _ ne
  reify^Î²Î¹Î¾ Ïƒ (injâ‚‚ T)   = reify^Î²Î¹Î¾â‹† Ïƒ T
\end{code}

Semantic application is slightly more interesting: we have to dispatch
depending on whether the function is a stuck term or not. In case it is,
we can reify the argument thus growing the spine of the stuck term.
Otherwise we have an Agda function ready to be applied and we do just
that. We proceed similarly for the definition of the semantical ``if then
else''.

\AgdaHide{
\begin{code}
infixr 5 _$^Î²Î¹Î¾_
\end{code}}
\begin{code}
_$^Î²Î¹Î¾_ : {Î“ : Con} {Ïƒ Ï„ : ty} (t : Î“ âŠ¨^Î²Î¹Î¾ Ïƒ `â†’ Ï„) (u : Î“ âŠ¨^Î²Î¹Î¾ Ïƒ) â†’ Î“ âŠ¨^Î²Î¹Î¾ Ï„
(injâ‚ ne)  $^Î²Î¹Î¾ u = injâ‚ $ ne `$ reify^Î²Î¹Î¾ _ u
(injâ‚‚ F)   $^Î²Î¹Î¾ u = F refl u

ifte^Î²Î¹Î¾ : {Î“ : Con} {Ïƒ : ty} (b : Î“ âŠ¨^Î²Î¹Î¾ `Bool) (l r : Î“ âŠ¨^Î²Î¹Î¾ Ïƒ) â†’ Î“ âŠ¨^Î²Î¹Î¾ Ïƒ
ifte^Î²Î¹Î¾ (injâ‚ ne) l r = injâ‚ $ `ifte ne (reify^Î²Î¹Î¾ _ l) (reify^Î²Î¹Î¾ _ r)
ifte^Î²Î¹Î¾ (injâ‚‚ T)  l r = if T then l else r
\end{code}

Finally, we have all the components necessary to show that evaluating
the term whilst abstaining from Î·-expanding all stuck terms is a
perfectly valid \AR{Semantics}. As usual, normalisation is defined
by composing reification and evaluation on the diagonal environment.

\begin{code}
Normalise^Î²Î¹Î¾ : Semantics _âŠ¨^Î²Î¹Î¾_ _âŠ¨^Î²Î¹Î¾_
Normalise^Î²Î¹Î¾ =
  record  { embed   = Î» Ïƒ â†’ reflect^Î²Î¹Î¾ Ïƒ âˆ˜ `var
          ; wk      = wk^Î²Î¹Î¾
          ; âŸ¦varâŸ§   = id
          ; _âŸ¦$âŸ§_   = _$^Î²Î¹Î¾_
          ; âŸ¦Î»âŸ§     = injâ‚‚
          ; âŸ¦âŸ¨âŸ©âŸ§    = injâ‚‚ âŸ¨âŸ©
          ; âŸ¦ttâŸ§    = injâ‚‚ true
          ; âŸ¦ffâŸ§    = injâ‚‚ false
          ; âŸ¦ifteâŸ§  = ifte^Î²Î¹Î¾ }

norm^Î²Î¹Î¾ : {Î“ : Con} (Ïƒ : ty) (t : Î“ âŠ¢ Ïƒ) â†’ Î“ âŠ¢[ R^Î²Î¹Î¾ ]^nf Ïƒ
norm^Î²Î¹Î¾ Ïƒ t = reify^Î²Î¹Î¾ Ïƒ $â€² Normalise^Î²Î¹Î¾ âŠ¨eval t
\end{code}

\subsection{Normalisation by Evaluation for Î²Î¹}

The decision to lazily apply the Î·-rule can be pushed further: one may
forgo using the Î¾-rule and simply perform weak-head normalisation. This
leads to pursuing the computation only when absolutely necessary e.g.
when the two terms compared for equality have matching head constructors
and one needs to inspect these constructors' arguments to conclude. For
that purpose, we introduce an inductive family describing terms in weak-head
normal forms. Naturally, it is possible to define weakening for these as
well as erasure functions \AF{erase^{whnf}} and \AF{erase^{whne}} targetting
\AD{\_âŠ¢\_} (their rather simple definitions are omitted here).

\begin{code}
infix 5 _âŠ¢^whne_ _âŠ¢^whnf_
data _âŠ¢^whne_ (Î“ : Con) (Ïƒ : ty) : Set where
  `var   : (v : Ïƒ âˆˆ Î“) â†’ Î“ âŠ¢^whne Ïƒ
  _`$_   : {Ï„ : ty} (t : Î“ âŠ¢^whne Ï„ `â†’ Ïƒ) (u : Î“ âŠ¢ Ï„) â†’ Î“ âŠ¢^whne Ïƒ
  `ifte  : (b : Î“ âŠ¢^whne `Bool) (l r : Î“ âŠ¢ Ïƒ) â†’ Î“ âŠ¢^whne Ïƒ

data _âŠ¢^whnf_ (Î“ : Con) : (Ïƒ : ty) â†’ Set where
  `embed  : {Ïƒ : ty} (t : Î“ âŠ¢^whne Ïƒ) â†’ Î“ âŠ¢^whnf Ïƒ
  `âŸ¨âŸ©     : Î“ âŠ¢^whnf `Unit
  `tt     : Î“ âŠ¢^whnf `Bool
  `ff     : Î“ âŠ¢^whnf `Bool
  `Î»      : {Ïƒ Ï„ : ty} (b : Î“ âˆ™ Ïƒ âŠ¢ Ï„) â†’ Î“ âŠ¢^whnf (Ïƒ `â†’ Ï„)

wk^whne : {Î” Î“ : Con} (inc : Î“ âŠ† Î”) {Ïƒ : ty} (ne : Î“ âŠ¢^whne Ïƒ) â†’ Î” âŠ¢^whne Ïƒ
wk^whnf : {Î” Î“ : Con} (inc : Î“ âŠ† Î”) {Ïƒ : ty} (ne : Î“ âŠ¢^whnf Ïƒ) â†’ Î” âŠ¢^whnf Ïƒ
\end{code}
\AgdaHide{
\begin{code}
wk^whne inc (`var v)        = `var $â€² wk^âˆˆ inc v
wk^whne inc (ne `$ u)       = wk^whne inc ne `$ wk^âŠ¢ inc u
wk^whne inc (`ifte ne l r)  = `ifte (wk^whne inc ne) (wk^âŠ¢ inc l) (wk^âŠ¢ inc r)

wk^whnf inc (`embed t)  = `embed $â€² wk^whne inc t
wk^whnf inc `âŸ¨âŸ©         = `âŸ¨âŸ©
wk^whnf inc `tt         = `tt
wk^whnf inc `ff         = `ff
wk^whnf inc (`Î» b)      = `Î» $â€² wk^âŠ¢ (pop! inc) b

erase^whne : {Î“ : Con} {Ïƒ : ty} (t : Î“ âŠ¢^whne Ïƒ) â†’ Î“ âŠ¢ Ïƒ
erase^whne (`var v)       = `var v
erase^whne (t `$ u)       = erase^whne t `$ u
erase^whne (`ifte t l r)  = `ifte (erase^whne t) l r

infix 5 _âŠ¨^Î²Î¹_ _âŠ¨^Î²Î¹â‹†_
\end{code}}

The model construction is quite similar to the previous one except
that source terms are now stored in the model. This means that from
an element of the model, one can pick either the reduced version of
the original term (i.e. a stuck term or the term's computational
content) or the original term itself. We exploit this ability most
notably at reification time where once we have obtained either a
head constructor (respectively a head variable), none of the subterms
need to be evaluated.

\begin{code}
mutual

  _âŠ¨^Î²Î¹_ : (Î“ : Con) (Ïƒ : ty) â†’ Set
  Î“ âŠ¨^Î²Î¹ Ïƒ  = Î“ âŠ¢ Ïƒ  Ã— (Î“ âŠ¢^whne Ïƒ âŠ Î“ âŠ¨^Î²Î¹â‹† Ïƒ)

  _âŠ¨^Î²Î¹â‹†_ : (Î“ : Con) (Ïƒ : ty) â†’ Set
  Î“ âŠ¨^Î²Î¹â‹† `Unit   = âŠ¤
  Î“ âŠ¨^Î²Î¹â‹† `Bool   = Bool
  Î“ âŠ¨^Î²Î¹â‹† Ïƒ `â†’ Ï„  = {Î” : Con} (inc : Î“ âŠ† Î”) (u : Î” âŠ¨^Î²Î¹ Ïƒ) â†’ Î” âŠ¨^Î²Î¹ Ï„
\end{code}

Once more, weakening is definable. Reflection of weak-head neutrals
is made possible by an easy lemma showing that erasure to terms is
possible.

\begin{code}
wk^Î²Î¹â‹† : {Î” Î“ : Con} (inc : Î“ âŠ† Î”) {Ïƒ : ty} (T : Î“ âŠ¨^Î²Î¹â‹† Ïƒ) â†’ Î” âŠ¨^Î²Î¹â‹† Ïƒ
wk^Î²Î¹â‹† inc {`Unit   } T = T
wk^Î²Î¹â‹† inc {`Bool   } T = T
wk^Î²Î¹â‹† inc {Ïƒ `â†’ Ï„  } T = Î» incâ€² â†’ T $â€² trans inc incâ€²

wk^Î²Î¹ : {Î” Î“ : Con}{Ïƒ : ty} (inc : Î“ âŠ† Î”) (T : Î“ âŠ¨^Î²Î¹ Ïƒ) â†’ Î” âŠ¨^Î²Î¹ Ïƒ
wk^Î²Î¹ inc (t , injâ‚ ne)  = wk^âŠ¢ inc t , injâ‚ (wk^whne inc ne)
wk^Î²Î¹ inc (t , injâ‚‚ T)   = wk^âŠ¢ inc t , injâ‚‚ (wk^Î²Î¹â‹† inc T)

reflect^Î²Î¹ : {Î“ : Con} (Ïƒ : ty) (t : Î“ âŠ¢^whne Ïƒ) â†’ Î“ âŠ¨^Î²Î¹ Ïƒ
reflect^Î²Î¹ Ïƒ t = erase^whne t , injâ‚ t
\end{code}

Reification is following the usual pattern; once more we avoid
Î·-expansion at all cost.

\begin{code}
mutual

  reify^Î²Î¹â‹† : {Î“ : Con} (Ïƒ : ty) (T : Î“ âŠ¨^Î²Î¹â‹† Ïƒ) â†’ Î“ âŠ¢^whnf Ïƒ
  reify^Î²Î¹â‹† `Unit     T = `âŸ¨âŸ©
  reify^Î²Î¹â‹† `Bool     T = if T then `tt else `ff
  reify^Î²Î¹â‹† (Ïƒ `â†’ Ï„)  T = `Î» $ projâ‚ $ T (step refl) varâ€¿0^Î²Î¹
    where varâ€¿0^Î²Î¹ = reflect^Î²Î¹ _ $ `var zero

  reify^Î²Î¹ : {Î“ : Con} (Ïƒ : ty) (T : Î“ âŠ¨^Î²Î¹ Ïƒ) â†’ Î“ âŠ¢^whnf Ïƒ
  reify^Î²Î¹ Ïƒ (t , injâ‚ ne) = `embed ne
  reify^Î²Î¹ Ïƒ (t , injâ‚‚ T)  = reify^Î²Î¹â‹† Ïƒ T
\end{code}

One important difference in the application rule with respect
to the previous subsection is that we do not grow the spine of
a stuck term using the reified argument but rather its \emph{source}
term thus staying true to the idea that we only head reduce
enough to expose either a constructor or a variable. The same
goes for \AF{ifte^{Î²Î¹}}.

\begin{code}
infixr 5 _$^Î²Î¹_
_$^Î²Î¹_ : {Î“ : Con} {Ïƒ Ï„ : ty} (t : Î“ âŠ¨^Î²Î¹ Ïƒ `â†’ Ï„) (u : Î“ âŠ¨^Î²Î¹ Ïƒ) â†’ Î“ âŠ¨^Î²Î¹ Ï„
(t , injâ‚ ne)  $^Î²Î¹ (u , U) = t `$ u , injâ‚ (ne `$ u)
(t , injâ‚‚ T)   $^Î²Î¹ (u , U) = t `$ u , projâ‚‚ (T refl (u , U))

ifte^Î²Î¹ : {Î“ : Con} {Ïƒ : ty} (b : Î“ âŠ¨^Î²Î¹ `Bool) (l r : Î“ âŠ¨^Î²Î¹ Ïƒ) â†’ Î“ âŠ¨^Î²Î¹ Ïƒ
ifte^Î²Î¹ (b , injâ‚ ne)  (l , L) (r , R) = `ifte b l r , injâ‚ (`ifte ne l r)
ifte^Î²Î¹ (b , injâ‚‚ B)   (l , L) (r , R) = `ifte b l r , (if B then L else R)


Normalise^Î²Î¹ : Semantics _âŠ¨^Î²Î¹_ _âŠ¨^Î²Î¹_
Normalise^Î²Î¹ =
  record  { embed   = Î» Ïƒ â†’ reflect^Î²Î¹ Ïƒ âˆ˜ `var
          ; wk      = wk^Î²Î¹
          ; âŸ¦varâŸ§   = id
          ; _âŸ¦$âŸ§_   = _$^Î²Î¹_
          ; âŸ¦Î»âŸ§     = Î» t â†’ `Î» (projâ‚ $ t (step refl) (reflect^Î²Î¹ _ $ `var zero)) , injâ‚‚ t
          ; âŸ¦âŸ¨âŸ©âŸ§    = `âŸ¨âŸ© , injâ‚‚ âŸ¨âŸ©
          ; âŸ¦ttâŸ§    = `tt  , injâ‚‚ true
          ; âŸ¦ffâŸ§    = `ff  , injâ‚‚ false
          ; âŸ¦ifteâŸ§  = ifte^Î²Î¹
          }

norm^Î²Î¹ : {Î“ : Con} (Ïƒ : ty) (t : Î“ âŠ¢ Ïƒ) â†’ Î“ âŠ¢^whnf Ïƒ
norm^Î²Î¹ Ïƒ t = reify^Î²Î¹ Ïƒ $â€² Normalise^Î²Î¹ âŠ¨eval t
\end{code}

\section{Proving Properties of Semantics}
\label{properties}

Thanks to the introduction of \AF{Semantics}, we have already saved
quite a bit of work by not reimplementing the same traversals over
and over again. But this disciplined approach to building models and
defining the associated evaluation functions can also help us refactor
the process of proving some properties of these semantics.

Instead of using proof scripts as Benton et al.~\cite{benton2012strongly}
do, we describe abstractly the constraints the logical relations~\cite{reynolds1983types}
defined on model (and environment) values have to respect for us to be
able to conclude that the evaluation of a term in related environments
produces related outputs. This gives us a generic proof framework to
state and prove, in one go, properties about all of these semantics.

Our first example of such a framework will stay simple on purpose.
However this does not mean that it is a meaningless exercise: the
result proven here will actually be useful in the following subsections
when considering more complex properties.

\subsection{The Synchronisation Relation}

This first presentation should give the reader a good idea of the
internal organisation of this type of setup before we move on to a
more involved one. The types involved might look a bit scary because
of the level of generality that we adopt but the idea is rather simple:
two \AR{Semantics} are said to be \emph{synchronisable} if, when
evaluating a term in related environments, they output related values.
The bulk of the work is to make this intuition formal.

The evidence that two \AR{Semantics} are \AR{Synchronisable} is
packaged in a record. The record is indexed by the two semantics
as well as three relations. The first relation (\AB{ğ“”^{R}_{AB}})
characterises the elements of the (respective) environment types
which are to be considered synchronised, the second (\AB{ğ“”^R})
explains what it means for two environments to be synchronised
and the last (\AB{ğ“œ^R}) describes what synchronisation means
in the model.

\begin{code}
record Synchronisable
  {â„“^EA â„“^MA â„“^EB â„“^MB : Level} {ğ“”^A : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“^EA} {ğ“œ^A : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“^MA} (ğ“¢^A : Semantics ğ“”^A ğ“œ^A)
  {ğ“”^B : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“^EB} {ğ“œ^B : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“^MB} (ğ“¢^B : Semantics ğ“”^B ğ“œ^B)
  {â„“^RE â„“^RM â„“^REAB : Level} (ğ“”^Râ€¿AB : {Î“ : Con} {Ïƒ : ty} (e^A : ğ“”^A Î“ Ïƒ) (e^B : ğ“”^B Î“ Ïƒ) â†’ Set â„“^REAB)
  (ğ“”^R : {Î” Î“ : Con} (e^A : Î” [ ğ“”^A ] Î“) (e^B : Î” [ ğ“”^B ] Î“) â†’ Set â„“^RE)
  (ğ“œ^R : {Î“ : Con} {Ïƒ : ty} (mA : ğ“œ^A Î“ Ïƒ) (mB : ğ“œ^B Î“ Ïƒ) â†’ Set â„“^RM) : Set (â„“^RE âŠ” â„“^RM âŠ” â„“^EA âŠ” â„“^EB âŠ” â„“^MA âŠ” â„“^MB âŠ” â„“^REAB) where
\end{code}

The record's fields are describing the structure these relations
need to have. The first topic of interest is the interaction
between \AB{ğ“”^R_{AB}} and \AB{ğ“”^R}. \ARF{ğ“”^R_{âˆ™}} states that
it should be possible to extend two synchronised environments as
long the elements we push onto them are themselves related by
\AB{ğ“”^R_{AB}}. \ARF{ğ“”^Râ€¿wk} states that two synchronised
environments can be weakened whilst staying synchronised.

\AgdaHide{
\begin{code}
  module SemA = Semantics ğ“¢^A
  module SemB = Semantics ğ“¢^B
  field
\end{code}}
\begin{code}
    ğ“”^Râ€¿âˆ™   :  {Î“ Î” : Con} {Ïƒ : ty} {Ï^A : Î” [ ğ“”^A ] Î“} {Ï^B : Î” [ ğ“”^B ] Î“} {u^A : ğ“”^A Î” Ïƒ} {u^B : ğ“”^B Î” Ïƒ} (Ï^R : ğ“”^R Ï^A Ï^B) (u^R : ğ“”^Râ€¿AB u^A u^B) â†’ ğ“”^R ([ ğ“”^A ] Ï^A `âˆ™ u^A) ([ ğ“”^B ] Ï^B `âˆ™ u^B)
    ğ“”^Râ€¿wk  :  {Î“ Î” Î˜ : Con} (inc : Î” âŠ† Î˜) {Ï^A : Î” [ ğ“”^A ] Î“} {Ï^B : Î” [ ğ“”^B ] Î“} (Ï^R : ğ“”^R Ï^A Ï^B) â†’
                ğ“”^R (wk[ SemA.wk ] inc Ï^A) (wk[ SemB.wk ] inc Ï^B)
\end{code}

We then have the relational counterparts of the term constructors.
In order to lighten the presentation, we will mostly focus on the
interesting ones and give only one example quite characteristic of
the other ones.

The first interesting case is the relational counterpart of the
\AIC{`var} constructor: it states that given two synchronised
environments, we indeed get synchronised values in the model by
looking up the values each one of these associates to a given
variable.

\begin{code}
    RâŸ¦varâŸ§    :  {Î“ Î” : Con} {Ïƒ : ty} (v : Ïƒ âˆˆ Î“) {Ï^A : Î” [ ğ“”^A ] Î“} {Ï^B : Î” [ ğ“”^B ] Î“} (Ï^R : ğ“”^R Ï^A Ï^B) â†’
                 ğ“œ^R (ğ“¢^A âŠ¨âŸ¦ `var v âŸ§ Ï^A) (ğ“¢^B âŠ¨âŸ¦ `var v âŸ§ Ï^B)
\end{code}

The second, and probably most interesting case, is the description
of the relational counterpart of the \AIC{`Î»}-abstraction which is
guided by the type of the \ARF{âŸ¦Î»âŸ§} combinator. It states that the
ability to evaluate the body of the Î» in weakened environments each
extended by related values and deliver synchronised values in the
model is enough to guarantee that evaluating the lambdas in the original
environments will deliver synchronised values.

\begin{code}
    RâŸ¦Î»âŸ§      :  {Î“ Î” : Con} {Ïƒ Ï„ : ty} (t : Î“ âˆ™ Ïƒ âŠ¢ Ï„) {Ï^A : Î” [ ğ“”^A ] Î“} {Ï^B : Î” [ ğ“”^B ] Î“} (Ï^R : ğ“”^R Ï^A Ï^B) â†’
                 (r :  {Î˜ : Con} (inc : Î” âŠ† Î˜) {u^A : ğ“”^A Î˜ Ïƒ} {u^B : ğ“”^B Î˜ Ïƒ} (u^R : ğ“”^Râ€¿AB u^A u^B) â†’
                       let Ï^Aâ€²  = [ ğ“”^A ] wk[ SemA.wk ] inc Ï^A `âˆ™ u^A
                           Ï^Bâ€²  = [ ğ“”^B ] wk[ SemB.wk ] inc Ï^B `âˆ™ u^B
                       in ğ“œ^R  (ğ“¢^A âŠ¨âŸ¦ t âŸ§ Ï^Aâ€²) (ğ“¢^B âŠ¨âŸ¦ t âŸ§ Ï^Bâ€²)) â†’
                 ğ“œ^R (ğ“¢^A âŠ¨âŸ¦ `Î» t âŸ§ Ï^A) (ğ“¢^B âŠ¨âŸ¦ `Î» t âŸ§ Ï^B)
\end{code}

All the remaining cases are similar. We show here the relational
counterpart of the application constructor: it states that given
two induction hypotheses (and the knowledge that the two environment
used are synchronised), one can combine them to obtain a proof
about the evaluation of an application-headed term.

\begin{code}
    RâŸ¦$âŸ§      :  {Î“ Î” : Con} {Ïƒ Ï„ : ty} (f : Î“ âŠ¢ Ïƒ `â†’ Ï„) (t : Î“ âŠ¢ Ïƒ) {Ï^A : Î” [ ğ“”^A ] Î“} {Ï^B : Î” [ ğ“”^B ] Î“} (Ï^R : ğ“”^R Ï^A Ï^B) â†’
                 ğ“œ^R (ğ“¢^A âŠ¨âŸ¦ f âŸ§ Ï^A) (ğ“¢^B âŠ¨âŸ¦ f âŸ§ Ï^B) â†’
                 ğ“œ^R (ğ“¢^A âŠ¨âŸ¦ t âŸ§ Ï^A) (ğ“¢^B âŠ¨âŸ¦ t âŸ§ Ï^B) â†’
                 ğ“œ^R (ğ“¢^A âŠ¨âŸ¦ f `$ t âŸ§ Ï^A) (ğ“¢^B âŠ¨âŸ¦ f `$ t âŸ§ Ï^B)
\end{code}
\AgdaHide{
\begin{code}
    RâŸ¦âŸ¨âŸ©âŸ§     :  {Î“ Î” : Con} {Ï^A : Î” [ ğ“”^A ] Î“} {Ï^B : Î” [ ğ“”^B ] Î“} (Ï^R : ğ“”^R Ï^A Ï^B) â†’
                 ğ“œ^R (ğ“¢^A âŠ¨âŸ¦ `âŸ¨âŸ© âŸ§ Ï^A) (ğ“¢^B âŠ¨âŸ¦ `âŸ¨âŸ© âŸ§ Ï^B)
    RâŸ¦ttâŸ§     :  {Î“ Î” : Con} {Ï^A : Î” [ ğ“”^A ] Î“} {Ï^B : Î” [ ğ“”^B ] Î“} (Ï^R : ğ“”^R Ï^A Ï^B) â†’
                 ğ“œ^R (ğ“¢^A âŠ¨âŸ¦ `tt âŸ§ Ï^A) (ğ“¢^B âŠ¨âŸ¦ `tt âŸ§ Ï^B)
    RâŸ¦ffâŸ§     :  {Î“ Î” : Con} {Ï^A : Î” [ ğ“”^A ] Î“} {Ï^B : Î” [ ğ“”^B ] Î“} (Ï^R : ğ“”^R Ï^A Ï^B) â†’
                 ğ“œ^R (ğ“¢^A âŠ¨âŸ¦ `ff âŸ§ Ï^A) (ğ“¢^B âŠ¨âŸ¦ `ff âŸ§ Ï^B)
    RâŸ¦ifteâŸ§   :  {Î“ Î” : Con} {Ïƒ : ty} (b : Î“ âŠ¢ `Bool) (l r : Î“ âŠ¢ Ïƒ) {Ï^A : Î” [ ğ“”^A ] Î“} {Ï^B : Î” [ ğ“”^B ] Î“} (Ï^R : ğ“”^R Ï^A Ï^B) â†’
                 ğ“œ^R (ğ“¢^A âŠ¨âŸ¦ b âŸ§ Ï^A) (ğ“¢^B âŠ¨âŸ¦ b âŸ§ Ï^B) â†’
                 ğ“œ^R (ğ“¢^A âŠ¨âŸ¦ l âŸ§ Ï^A) (ğ“¢^B âŠ¨âŸ¦ l âŸ§ Ï^B) â†’
                 ğ“œ^R (ğ“¢^A âŠ¨âŸ¦ r âŸ§ Ï^A) (ğ“¢^B âŠ¨âŸ¦ r âŸ§ Ï^B) â†’
                 ğ“œ^R (ğ“¢^A âŠ¨âŸ¦ `ifte b l r âŸ§ Ï^A) (ğ“¢^B âŠ¨âŸ¦ `ifte b l r âŸ§ Ï^B)
\end{code}}

For this specification to be useful, we need to verify that it is indeed
possible for us to benefit from its introduction which we can conclude
based on two observations. First, our ability to prove a fundamental lemma
stating that given relations satisfying this specification, the evaluation
of a term in related environments yields related values; second, our ability
to find with various instances of such synchronised semantics. Let us start
with the fundamental lemma.

\subsubsection{Fundamental Lemma of Synchronisable Semantics}

The fundamental lemma is indeed provable. We introduce a \AM{Synchronised}
module parametrised by a record packing the evidence that two semantics are
\AR{Synchronisable}. This allows us to bring all of the corresponding relational
counterpart of term constructors into scope by \AK{open}ing the record. The
traversal then uses them to combine the induction hypotheses arising structurally.

\begin{code}
module Synchronised {â„“^EA â„“^MA â„“^EB â„“^MB : Level} {ğ“”^A : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“^EA} {ğ“œ^A : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“^MA} {ğ“¢^A : Semantics ğ“”^A ğ“œ^A} {ğ“”^B : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“^EB} {ğ“œ^B : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“^MB} {ğ“¢^B : Semantics ğ“”^B ğ“œ^B} {â„“^RE â„“^RM â„“^REAB : Level} {ğ“”^Râ€¿AB : {Î“ : Con} {Ïƒ : ty} (e^A : ğ“”^A Î“ Ïƒ) (e^B : ğ“”^B Î“ Ïƒ) â†’ Set â„“^REAB} {ğ“”^R : {Î” Î“ : Con} (e^A : Î” [ ğ“”^A ] Î“) (e^B : Î” [ ğ“”^B ] Î“) â†’ Set â„“^RE} {ğ“œ^R : {Î“ : Con} {Ïƒ : ty} (mA : ğ“œ^A Î“ Ïƒ) (mB : ğ“œ^B Î“ Ïƒ) â†’ Set â„“^RM} (rel : Synchronisable ğ“¢^A ğ“¢^B ğ“”^Râ€¿AB ğ“”^R ğ“œ^R) where
  open Synchronisable rel

  lemma :  {Î“ Î” : Con} {Ïƒ : ty} (t : Î“ âŠ¢ Ïƒ) {Ï^A : Î” [ ğ“”^A ] Î“} {Ï^B : Î” [ ğ“”^B ] Î“} (Ï^R : ğ“”^R Ï^A Ï^B) â†’ ğ“œ^R (ğ“¢^A âŠ¨âŸ¦ t âŸ§ Ï^A) (ğ“¢^B âŠ¨âŸ¦ t âŸ§ Ï^B)
  lemma (`var v)       Ï^R = RâŸ¦varâŸ§ v Ï^R
  lemma (f `$ t)       Ï^R = RâŸ¦$âŸ§ f t Ï^R (lemma f Ï^R) (lemma t Ï^R)
  lemma (`Î» t)         Ï^R = RâŸ¦Î»âŸ§ t Ï^R $ Î» inc u^R â†’ lemma t (ğ“”^Râ€¿âˆ™ (ğ“”^Râ€¿wk inc Ï^R) u^R)
  lemma `âŸ¨âŸ©            Ï^R = RâŸ¦âŸ¨âŸ©âŸ§ Ï^R
  lemma `tt            Ï^R = RâŸ¦ttâŸ§ Ï^R
  lemma `ff            Ï^R = RâŸ¦ffâŸ§ Ï^R
  lemma (`ifte b l r)  Ï^R = RâŸ¦ifteâŸ§ b l r Ï^R (lemma b Ï^R) (lemma l Ï^R) (lemma r Ï^R)
\end{code}

\subsubsection{Examples of Synchronisable Semantics}

Our first example of two synchronisable semantics is proving the
fact that \AF{Renaming} and \AF{Substitution} have precisely the
same behaviour whenever the environment we use for \AF{Substitution}
is only made up of variables. The (mundane) proofs which mostly
consist of using the congruence of propositional equality are
left out. We show with the lemma \AF{RenamingIsASubstitution} how
the result is derived directly from the fundamental lemma of
\AR{Synchronisable} semantics.

\begin{code}
SynchronisableRenamingSubstitution : Synchronisable Renaming Substitution
  (Î» v t â†’ `var v â‰¡ t)
  (Î» Ï^A Ï^B â†’ (Ïƒ : ty) (pr : Ïƒ âˆˆ _) â†’ `var (Ï^A Ïƒ pr) â‰¡ Ï^B Ïƒ pr)
  _â‰¡_
\end{code}
\AgdaHide{
\begin{code}
SynchronisableRenamingSubstitution =
  record
    { ğ“”^Râ€¿âˆ™   = Î» Ï^R u^R â†’ [ u^R , Ï^R ]
    ; ğ“”^Râ€¿wk  = Î» inc Ï^R Ïƒ pr â†’ PEq.cong (wk^âŠ¢ inc) (Ï^R Ïƒ pr)
    ; RâŸ¦varâŸ§    = Î» v Ï^R â†’ Ï^R _ v
    ; RâŸ¦$âŸ§      = Î» _ _ _ â†’ PEq.congâ‚‚ _`$_
    ; RâŸ¦Î»âŸ§      = Î» _  Ï^R r â†’ PEq.cong `Î» (r (step refl) PEq.refl)
    ; RâŸ¦âŸ¨âŸ©âŸ§     = Î» _  â†’ PEq.refl
    ; RâŸ¦ttâŸ§     = Î» _  â†’ PEq.refl
    ; RâŸ¦ffâŸ§     = Î» _  â†’ PEq.refl
    ; RâŸ¦ifteâŸ§   = Î» _ _ _ _ eqb eql â†’ PEq.congâ‚‚ (uncurry `ifte) (PEq.congâ‚‚ _,_ eqb eql)
    }
\end{code}}

We show with the lemma \AF{RenamingIsASubstitution} how the result
we meant to prove is derived directly from the fundamental lemma of
\AR{Synchronisable} semantics:

\begin{code}
RenamingIsASubstitution : {Î“ Î” : Con} {Ïƒ : ty} (t : Î“ âŠ¢ Ïƒ) (Ï : Î” [ flip (_âˆˆ_) ] Î“) â†’
  Renaming âŠ¨âŸ¦ t âŸ§ Ï â‰¡ Substitution âŠ¨âŸ¦ t âŸ§ (Î» Ïƒ â†’ `var âˆ˜ Ï Ïƒ)
RenamingIsASubstitution t Ï = RenSubst.lemma t (Î» Ïƒ pr â†’ PEq.refl)
  where module RenSubst = Synchronised SynchronisableRenamingSubstitution
\end{code}


Another example of a synchronisable semantics is Normalisation by Evaluation
which can be synchronised with itself. This may appear like mindless symbol
pushing but it is actually crucial to prove such a theorem: we can only
define a Partial Equivalence Relation~\cite{mitchell1996foundations} (PER)
on the model used to implement Normalisation by Evaluation. The proofs of
the more complex properties of the procedure will rely heavily on the fact
that the exotic elements that may exist in the host language are actually
never produced by the evaluation function run on a term as long as all the
elements of the environment used were, themselves, not exotic i.e. equal to
themselves according to the PER.

We start with the definition of the PER for the model. It is constructed
by induction on the type and ensures that terms which behave the same
extensionally are declared equal. Two values of type \AIC{`Unit} are
always trivially equal;  values of type \AIC{`Bool} are normal forms
and are declared equal when they are effectively syntactically the same;
finally functions are equal whenever given equal inputs they yield equal
outputs.

\begin{code}
EQREL : (Î“ : Con) (Ïƒ : ty) (T U : Î“ âŠ¨^Î²Î¹Î¾Î· Ïƒ) â†’ Set
EQREL Î“ `Unit     T U = âŠ¤
EQREL Î“ `Bool     T U = T â‰¡ U
EQREL Î“ (Ïƒ `â†’ Ï„)  T U =  {Î” : Con} (inc : Î“ âŠ† Î”) {V W : Î” âŠ¨^Î²Î¹Î¾Î· Ïƒ} (eqVW : EQREL Î” Ïƒ V W) â†’
                         EQREL Î” Ï„ (T inc V) (U inc W)
\end{code}

It is indeed a PER as witnessed by the (omitted here) \AF{symEQREL} and
\AF{transEQREL} functions and it respects weakening as \AF{wk^{EQREL}} shows.

\begin{code}
symEQREL : {Î“ : Con} (Ïƒ : ty) {S T : Î“ âŠ¨^Î²Î¹Î¾Î· Ïƒ} â†’ EQREL Î“ Ïƒ S T â†’ EQREL Î“ Ïƒ T S
\end{code}
\AgdaHide{
\begin{code}
symEQREL `Unit     eq = âŸ¨âŸ©
symEQREL `Bool     eq = PEq.sym eq
symEQREL (Ïƒ `â†’ Ï„)  eq = Î» inc eqVW â†’ symEQREL Ï„ (eq inc (symEQREL Ïƒ eqVW))
\end{code}}\vspace{-2.5em}%ugly but it works!
\begin{code}
transEQREL : {Î“ : Con} (Ïƒ : ty) {S T U : Î“ âŠ¨^Î²Î¹Î¾Î· Ïƒ} â†’ EQREL Î“ Ïƒ S T â†’ EQREL Î“ Ïƒ T U â†’ EQREL Î“ Ïƒ S U
\end{code}
\AgdaHide{
\begin{code}
  -- We are in PER so reflEQREL is not provable
  -- but as soon as EQREL Ïƒ V W then EQREL Ïƒ V V
reflEQREL : {Î“ : Con} (Ïƒ : ty) {S T : Î“ âŠ¨^Î²Î¹Î¾Î· Ïƒ} â†’ EQREL Î“ Ïƒ S T â†’ EQREL Î“ Ïƒ S S

transEQREL `Unit     eqâ‚ eqâ‚‚ = âŸ¨âŸ©
transEQREL `Bool     eqâ‚ eqâ‚‚ = PEq.trans eqâ‚ eqâ‚‚
transEQREL (Ïƒ `â†’ Ï„)  eqâ‚ eqâ‚‚ =
  Î» inc eqVW â†’ transEQREL Ï„ (eqâ‚ inc (reflEQREL Ïƒ eqVW)) (eqâ‚‚ inc eqVW)

reflEQREL Ïƒ eq = transEQREL Ïƒ eq (symEQREL Ïƒ eq)
\end{code}}\vspace{-2.5em}%ugly but it works!
\begin{code}
wk^EQREL :  {Î” Î“ : Con} (Ïƒ : ty) (inc : Î“ âŠ† Î”) {T U : Î“ âŠ¨^Î²Î¹Î¾Î· Ïƒ} â†’ EQREL Î“ Ïƒ T U â†’ EQREL Î” Ïƒ (wk^Î²Î¹Î¾Î· Ïƒ inc T) (wk^Î²Î¹Î¾Î· Ïƒ inc U)
\end{code}
\AgdaHide{
\begin{code}
wk^EQREL `Unit     inc eq = âŸ¨âŸ©
wk^EQREL `Bool     inc eq = PEq.cong (wk^nf inc) eq
wk^EQREL (Ïƒ `â†’ Ï„)  inc eq = Î» incâ€² eqVW â†’ eq (trans inc incâ€²) eqVW
\end{code}}

The interplay of reflect and reify with this notion of equality has
to be described in one go because of their being mutually defined.
It confirms our claim that \AF{EQREL} is indeed an appropriate notion
of semantic equality.

\begin{code}
reify^EQREL    :  {Î“ : Con} (Ïƒ : ty) {T U : Î“ âŠ¨^Î²Î¹Î¾Î· Ïƒ} â†’ EQREL Î“ Ïƒ T U â†’ reify^Î²Î¹Î¾Î· Ïƒ T â‰¡ reify^Î²Î¹Î¾Î· Ïƒ U
reflect^EQREL  :  {Î“ : Con} (Ïƒ : ty) {t u : Î“ âŠ¢[ R^Î²Î¹Î¾Î· ]^ne Ïƒ} â†’ t â‰¡ u â†’ EQREL Î“ Ïƒ (reflect^Î²Î¹Î¾Î· Ïƒ t) (reflect^Î²Î¹Î¾Î· Ïƒ u)
\end{code}
\AgdaHide{
\begin{code}
reify^EQREL `Unit     EQTU = PEq.refl
reify^EQREL `Bool     EQTU = EQTU
reify^EQREL (Ïƒ `â†’ Ï„)  EQTU = PEq.cong `Î» $ reify^EQREL Ï„ $ EQTU (step refl) $ reflect^EQREL Ïƒ PEq.refl

reflect^EQREL `Unit     eq = âŸ¨âŸ©
reflect^EQREL `Bool     eq = PEq.cong (`embed _) eq
reflect^EQREL (Ïƒ `â†’ Ï„)  eq = Î» inc rel â†’ reflect^EQREL Ï„ $ PEq.congâ‚‚ _`$_ (PEq.cong (wk^ne inc) eq) (reify^EQREL Ïƒ rel)

ifteRelNorm :
      {Î“ Î” : Con} {Ïƒ : ty} (b : Î“ âŠ¢ `Bool) (l r : Î“ âŠ¢ Ïƒ)
      {Ï^A Ï^B : Î” [ _âŠ¨^Î²Î¹Î¾Î·_ ] Î“} â†’
      ((Ïƒâ‚ : ty) (pr : Ïƒâ‚ âˆˆ Î“) â†’ EQREL Î” Ïƒâ‚ (Ï^A Ïƒâ‚ pr) (Ï^B Ïƒâ‚ pr)) â†’
      Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ b âŸ§ Ï^A â‰¡ Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ b âŸ§ Ï^B â†’
      EQREL Î” Ïƒ (Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ l âŸ§ Ï^A) (Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ l âŸ§ Ï^B) â†’
      EQREL Î” Ïƒ (Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ r âŸ§ Ï^A) (Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ r âŸ§ Ï^B) â†’
      EQREL Î” Ïƒ (Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ `ifte b l r âŸ§ Ï^A)
      (Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ `ifte b l r âŸ§ Ï^B)
ifteRelNorm b l r {Ï^A} {Ï^B} Ï^R eqb eql eqr
  with Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ b âŸ§ Ï^A
     | Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ b âŸ§ Ï^B
ifteRelNorm b l r Ï^R PEq.refl eql eqr | `embed _ t | `embed _ .t =
  reflect^EQREL _ (PEq.congâ‚‚ (uncurry `ifte) (PEq.congâ‚‚ _,_ PEq.refl (reify^EQREL _ eql)) (reify^EQREL _ eqr))
ifteRelNorm b l r Ï^R () eql eqr | `embed _ t | `tt
ifteRelNorm b l r Ï^R () eql eqr | `embed _ t | `ff
ifteRelNorm b l r Ï^R () eql eqr | `tt | `embed _ t
ifteRelNorm b l r Ï^R PEq.refl eql eqr | `tt | `tt = eql
ifteRelNorm b l r Ï^R () eql eqr | `tt | `ff
ifteRelNorm b l r Ï^R () eql eqr | `ff | `embed _ t
ifteRelNorm b l r Ï^R () eql eqr | `ff | `tt
ifteRelNorm b l r Ï^R PEq.refl eql eqr | `ff | `ff = eqr
\end{code}}

And that's enough to prove that evaluating a term in two
environments related in a pointwise manner by \AF{EQREL}
yields two semantic objects themselves related by \AF{EQREL}.

\begin{code}
SynchronisableNormalise : Synchronisable Normalise^Î²Î¹Î¾Î· Normalise^Î²Î¹Î¾Î·
  (EQREL _ _)
  (Î» Ï^A Ï^B â†’ (Ïƒ : ty) (pr : Ïƒ âˆˆ _) â†’ EQREL _ Ïƒ (Ï^A Ïƒ pr) (Ï^B Ïƒ pr))
  (EQREL _ _)
\end{code}
\AgdaHide{
\begin{code}
SynchronisableNormalise =
  record  { ğ“”^Râ€¿âˆ™   = Î» Ï^R u^R â†’ [ u^R , Ï^R ]
          ; ğ“”^Râ€¿wk  = Î» inc Ï^R Ïƒ pr â†’ wk^EQREL Ïƒ inc (Ï^R Ïƒ pr)
          ; RâŸ¦varâŸ§   = Î» v Ï^R â†’ Ï^R _ v
          ; RâŸ¦$âŸ§     = Î» _ _ _ f â†’ f refl
          ; RâŸ¦Î»âŸ§     = Î» _ _ r â†’ r
          ; RâŸ¦âŸ¨âŸ©âŸ§    = Î» _ â†’ âŸ¨âŸ©
          ; RâŸ¦ttâŸ§    = Î» _ â†’ PEq.refl
          ; RâŸ¦ffâŸ§    = Î» _ â†’ PEq.refl
          ; RâŸ¦ifteâŸ§  = ifteRelNorm }
\end{code}}

We omit the details of the easy proof but still recall the type
of the corollary of the fundamental lemma one obtains in this
case:

\begin{code}
refl^Î²Î¹Î¾Î· :  {Î“ Î” : Con} {Ïƒ : ty} (t : Î“ âŠ¢ Ïƒ) {Ï^A Ï^B : Î” [ _âŠ¨^Î²Î¹Î¾Î·_ ] Î“} (Ï^R : (Ïƒ : ty) (pr : Ïƒ âˆˆ Î“) â†’ EQREL Î” Ïƒ (Ï^A Ïƒ pr) (Ï^B Ïƒ pr)) â†’
             EQREL Î” Ïƒ (Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ t âŸ§ Ï^A) (Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ t âŸ§ Ï^B)
refl^Î²Î¹Î¾Î· t Ï^R = ReflNorm.lemma t Ï^R
  where module ReflNorm = Synchronised SynchronisableNormalise
\end{code}


We can now move on to the more complex example of a proof
framework built generically over our notion of \AF{Semantics}

\subsection{Fusions of Evaluations}

When studying the meta-theory of a calculus, one systematically
needs to prove fusion lemmas for various semantics. For instance,
Benton et al.~\cite{benton2012strongly} prove six such lemmas
relating renaming, substitution and a typeful semantics embedding
their calculus into Coq. This observation naturally led us to
defining a fusion framework describing how to relate three semantics:
the pair we want to run sequentially and the third one they correspond
to. The fundamental lemma we prove can then be instantiated six times
to derive the corresponding lemmas.

The evidence that \AB{ğ“¢^A}, \AB{ğ“¢^B} and \AB{ğ“¢^C} are such
that \AB{ğ“¢^A} followed by \AB{ğ“¢^B} can be said to be equivalent
to \AB{ğ“¢^C} (e.g. think \AF{Substitution} followed by \AF{Renaming}
can be reduced to \AF{Substitution}) is packed in a record
\AR{Fusable} indexed by the three semantics but also three
relations. The first one (\AB{ğ“”^R_{BC}}) states what it means
for two environment values of \AB{ğ“¢^B} and \AB{ğ“¢^C} respectively
to be related. The second one (\AB{ğ“”^R}) characterises the triples
of environments (one for each one of the semantics) which are
compatible. Finally, the last one (\AB{ğ“œ^R}) relates values
in \AB{ğ“¢^B} and \AB{ğ“¢^C}'s respective models.

\begin{code}
record Fusable
  {â„“^EA â„“^MA â„“^EB â„“^MB â„“^EC â„“^MC â„“^RE â„“^REBC â„“^RM : Level} {ğ“”^A : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“^EA} {ğ“”^B : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“^EB} {ğ“”^C : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“^EC} {ğ“œ^A : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“^MA} {ğ“œ^B : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“^MB} {ğ“œ^C : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“^MC} (ğ“¢^A      : Semantics ğ“”^A ğ“œ^A)
  (ğ“¢^B : Semantics ğ“”^B ğ“œ^B)
  (ğ“¢^C : Semantics ğ“”^C ğ“œ^C)
  (ğ“”^Râ€¿BC : {Î“ : Con} {Ïƒ : ty} (e^B : ğ“”^B Î“ Ïƒ) (e^C : ğ“”^C Î“ Ïƒ) â†’ Set â„“^REBC)
  (ğ“”^R :  {Î˜ Î” Î“ : Con} (Ï^A : Î” [ ğ“”^A ] Î“) (Ï^B : Î˜ [ ğ“”^B ] Î”) (Ï^C : Î˜ [ ğ“”^C ] Î“) â†’ Set â„“^RE)
  (ğ“œ^R : {Î“ : Con} {Ïƒ : ty} (m^B : ğ“œ^B Î“ Ïƒ) (m^C : ğ“œ^C Î“ Ïƒ) â†’ Set â„“^RM)
  : Set (â„“^RM âŠ” â„“^RE âŠ” â„“^EC âŠ” â„“^EB âŠ” â„“^EA âŠ” â„“^MA âŠ” â„“^REBC) where
\end{code}
\AgdaHide{
\begin{code}
  module SemA = Semantics ğ“¢^A
  module SemB = Semantics ğ“¢^B
  module SemC = Semantics ğ“¢^C
  field
\end{code}}

Similarly to the previous section, most of the fields of this
record describe what structure these relations need to have.
However, we start with something slightly different: given that
we are planing to run the \AR{Semantics} \AB{ğ“¢^B} \emph{after}
having run \AB{ğ“¢^A}, we need a way to extract a term from an
element of \AB{ğ“¢^A}'s model. Our first field is therefore
\ARF{reify^A}:

\begin{code}
    reify^A    : {Î“ : Con} {Ïƒ : ty} (m : ğ“œ^A Î“ Ïƒ) â†’ Î“ âŠ¢ Ïƒ
\end{code}

Then come two constraints dealing with the relations talking
about evaluation environments. \ARF{ğ“”^Râ€¿âˆ™} tells us how to
extend related environments: one should be able to push related
values onto the environments for \AB{ğ“¢^B} and \AB{ğ“¢^C} whilst
merely extending the one for \AB{ğ“¢^A} with a token value generated
using \ARF{embed}.

\ARF{ğ“”^Râ€¿wk} guarantees that it is always possible to weaken
the environments for \AB{ğ“¢^B} and \AB{ğ“¢^C} in a \AB{ğ“”^R}
preserving manner.

\begin{code}
    ğ“”^Râ€¿âˆ™   :  {Î“ Î” Î˜ : Con} {Ïƒ : ty} {Ï^A : Î” [ ğ“”^A ] Î“} {Ï^B : Î˜ [ ğ“”^B ] Î”} {Ï^C : Î˜ [ ğ“”^C ] Î“} {u^B : ğ“”^B Î˜ Ïƒ} {u^C : ğ“”^C Î˜ Ïƒ} (Ï^R : ğ“”^R Ï^A Ï^B Ï^C) (u^R : ğ“”^Râ€¿BC u^B u^C) â†’
                ğ“”^R  ([ ğ“”^A ]  wk[ SemA.wk ] (step refl) Ï^A `âˆ™ SemA.embed Ïƒ zero)
                      ([ ğ“”^B ]  Ï^B `âˆ™ u^B) ([ ğ“”^C ]  Ï^C `âˆ™ u^C)

    ğ“”^Râ€¿wk  :  {Î“ Î” Î˜ E : Con} (inc : Î˜ âŠ† E) {Ï^A : Î” [ ğ“”^A ] Î“} {Ï^B : Î˜ [ ğ“”^B ] Î”} {Ï^C : Î˜ [ ğ“”^C ] Î“} (Ï^R : ğ“”^R Ï^A Ï^B Ï^C) â†’
               ğ“”^R Ï^A (wk[ SemB.wk ] inc Ï^B) (wk[ SemC.wk ] inc Ï^C)
\end{code}

Then we have the relational counterpart of the various term
constructors. As with the previous section, only a handful of
them are out of the ordinary. We will start with the \AIC{`var}
case. It states that fusion indeed happens when evaluating a
variable using related environments.

\begin{code}
    RâŸ¦varâŸ§  :  {Î“ Î” Î˜ : Con} {Ïƒ : ty} (v : Ïƒ âˆˆ Î“) {Ï^A : Î” [ ğ“”^A ] Î“} {Ï^B : Î˜ [ ğ“”^B ] Î”} {Ï^C : Î˜ [ ğ“”^C ] Î“} (Ï^R : ğ“”^R Ï^A Ï^B Ï^C) â†’
               ğ“œ^R (ğ“¢^B âŠ¨âŸ¦ reify^A (ğ“¢^A âŠ¨âŸ¦ `var v âŸ§ Ï^A) âŸ§ Ï^B) (ğ“¢^C âŠ¨âŸ¦ `var v âŸ§ Ï^C)
\end{code}

The \AIC{`Î»}-case puts some rather strong restrictions on the way
the Î»-abstraction's body may be used by \AB{ğ“¢^A}: we assume it
is evaluated in an environment weakened by one variable and extended
using \AB{ğ“¢^A}'s \ARF{embed}. But it is quite natural to have these
restrictions: given that \ARF{reify^A} quotes the result back, we are
expecting this type of evaluation in an extended context (i.e. under
one lambda). And it turns out that this is indeed enough for all of
our examples.
The evaluation environments used by the semantics \AB{ğ“¢^B} and \AB{ğ“¢^C}
on the other can be arbitrarily weakened before being extended with related
values to be substituted for the variable bound by the \AIC{`Î»}.

\begin{code}
    RâŸ¦Î»âŸ§    :
      {Î“ Î” Î˜ : Con} {Ïƒ Ï„ : ty} (t : Î“ âˆ™ Ïƒ âŠ¢ Ï„) {Ï^A : Î” [ ğ“”^A ] Î“} {Ï^B : Î˜ [ ğ“”^B ] Î”} {Ï^C : Î˜ [ ğ“”^C ] Î“} (Ï^R : ğ“”^R Ï^A Ï^B Ï^C) â†’
      (r :  {E : Con} (inc : Î˜ âŠ† E) {u^B : ğ“”^B E Ïƒ} {u^C : ğ“”^C E Ïƒ} (u^R : ğ“”^Râ€¿BC u^B u^C) â†’
            let  Ï^Aâ€² =  [ ğ“”^A ] wk[ SemA.wk ] (step refl) Ï^A `âˆ™ SemA.embed Ïƒ zero
                 Ï^Bâ€² =  [ ğ“”^B ] wk[ SemB.wk ] inc Ï^B `âˆ™ u^B
                 Ï^Câ€² =  [ ğ“”^C ] wk[ SemC.wk ] inc Ï^C `âˆ™ u^C
            in ğ“œ^R (ğ“¢^B âŠ¨âŸ¦ reify^A (ğ“¢^A âŠ¨âŸ¦ t âŸ§ Ï^Aâ€²) âŸ§ Ï^Bâ€²) (ğ“¢^C âŠ¨âŸ¦ t âŸ§ Ï^Câ€²)) â†’
      ğ“œ^R (ğ“¢^B âŠ¨âŸ¦ reify^A (ğ“¢^A âŠ¨âŸ¦ `Î» t âŸ§ Ï^A) âŸ§ Ï^B) (ğ“¢^C âŠ¨âŸ¦ `Î» t âŸ§ Ï^C)
\end{code}

The other cases are just a matter of stating that, given the
expected induction hypotheses, one can deliver a proof that
fusion can happen on the compound expression.

\AgdaHide{
\begin{code}
    RâŸ¦$âŸ§    : {Î“ Î” Î˜ : Con} {Ïƒ Ï„ : ty} (f : Î“ âŠ¢ Ïƒ `â†’ Ï„) (t : Î“ âŠ¢ Ïƒ)
            {Ï^A : Î” [ ğ“”^A ] Î“} {Ï^B : Î˜ [ ğ“”^B ] Î”} {Ï^C : Î˜ [ ğ“”^C ] Î“} â†’
             (Ï^R : ğ“”^R Ï^A Ï^B Ï^C) â†’
            ğ“œ^R (ğ“¢^B âŠ¨âŸ¦ reify^A (ğ“¢^A âŠ¨âŸ¦ f âŸ§ Ï^A) âŸ§ Ï^B)
                   (ğ“¢^C âŠ¨âŸ¦ f âŸ§ Ï^C) â†’
            ğ“œ^R (ğ“¢^B âŠ¨âŸ¦ reify^A (ğ“¢^A âŠ¨âŸ¦ t âŸ§ Ï^A) âŸ§ Ï^B) (ğ“¢^C âŠ¨âŸ¦ t âŸ§ Ï^C) â†’
            ğ“œ^R (ğ“¢^B âŠ¨âŸ¦ reify^A (ğ“¢^A âŠ¨âŸ¦ f `$ t âŸ§ Ï^A) âŸ§ Ï^B) (ğ“¢^C âŠ¨âŸ¦ f `$ t âŸ§ Ï^C)

    RâŸ¦âŸ¨âŸ©âŸ§   : {Î“ Î” Î˜ : Con} {Ï^A : Î” [ ğ“”^A ] Î“} {Ï^B : Î˜ [ ğ“”^B ] Î”} {Ï^C : Î˜ [ ğ“”^C ] Î“} â†’
             (Ï^R : ğ“”^R Ï^A Ï^B Ï^C) â†’
            ğ“œ^R (ğ“¢^B âŠ¨âŸ¦ reify^A (ğ“¢^A âŠ¨âŸ¦ `âŸ¨âŸ© âŸ§ Ï^A) âŸ§ Ï^B) (ğ“¢^C âŠ¨âŸ¦ `âŸ¨âŸ© âŸ§ Ï^C)
    RâŸ¦ttâŸ§   : {Î“ Î” Î˜ : Con} {Ï^A : Î” [ ğ“”^A ] Î“} {Ï^B : Î˜ [ ğ“”^B ] Î”} {Ï^C : Î˜ [ ğ“”^C ] Î“} â†’
             (Ï^R : ğ“”^R Ï^A Ï^B Ï^C) â†’
            ğ“œ^R (ğ“¢^B âŠ¨âŸ¦ reify^A (ğ“¢^A âŠ¨âŸ¦ `tt âŸ§ Ï^A) âŸ§ Ï^B) (ğ“¢^C âŠ¨âŸ¦ `tt âŸ§ Ï^C)
    RâŸ¦ffâŸ§   : {Î“ Î” Î˜ : Con} {Ï^A : Î” [ ğ“”^A ] Î“} {Ï^B : Î˜ [ ğ“”^B ] Î”} {Ï^C : Î˜ [ ğ“”^C ] Î“} â†’
             (Ï^R : ğ“”^R Ï^A Ï^B Ï^C) â†’
            ğ“œ^R (ğ“¢^B âŠ¨âŸ¦ reify^A (ğ“¢^A âŠ¨âŸ¦ `ff âŸ§ Ï^A) âŸ§ Ï^B) (ğ“¢^C âŠ¨âŸ¦ `ff âŸ§ Ï^C)
    RâŸ¦ifteâŸ§ : {Î“ Î” Î˜ : Con} {Ïƒ : ty} (b : Î“ âŠ¢ `Bool) (l r : Î“ âŠ¢ Ïƒ)
            {Ï^A : Î” [ ğ“”^A ] Î“} {Ï^B : Î˜ [ ğ“”^B ] Î”} {Ï^C : Î˜ [ ğ“”^C ] Î“} â†’
             (Ï^R : ğ“”^R Ï^A Ï^B Ï^C) â†’
            ğ“œ^R (ğ“¢^B âŠ¨âŸ¦ reify^A (ğ“¢^A âŠ¨âŸ¦ b âŸ§ Ï^A) âŸ§ Ï^B) (ğ“¢^C âŠ¨âŸ¦ b âŸ§ Ï^C) â†’
            ğ“œ^R (ğ“¢^B âŠ¨âŸ¦ reify^A (ğ“¢^A âŠ¨âŸ¦ l âŸ§ Ï^A) âŸ§ Ï^B) (ğ“¢^C âŠ¨âŸ¦ l âŸ§ Ï^C) â†’
            ğ“œ^R (ğ“¢^B âŠ¨âŸ¦ reify^A (ğ“¢^A âŠ¨âŸ¦ r âŸ§ Ï^A) âŸ§ Ï^B) (ğ“¢^C âŠ¨âŸ¦ r âŸ§ Ï^C) â†’
            ğ“œ^R (ğ“¢^B âŠ¨âŸ¦ reify^A (ğ“¢^A âŠ¨âŸ¦ `ifte b l r âŸ§ Ï^A) âŸ§ Ï^B) (ğ“¢^C âŠ¨âŸ¦ `ifte b l r âŸ§ Ï^C)
\end{code}}

\subsubsection{Fundamental Lemma of Fusable Semantics}

As with synchronisation, we measure the usefulness of this framework
by the fact that we can prove its fundamental lemma first and that
we get useful theorems out of it second. Once again, having carefully
identified what the constraints should be, proving the fundamental
lemma turns out to amount to a simple traversal we choose to omit here.

\begin{code}
module Fusion {â„“^EA â„“^MA â„“^EB â„“^MB â„“^EC â„“^MC â„“^RE â„“^REB â„“^RM : Level} {ğ“”^A : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“^EA} {ğ“”^B : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“^EB} {ğ“”^C : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“^EC} {ğ“œ^A : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“^MA} {ğ“œ^B : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“^MB} {ğ“œ^C : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“^MC} {ğ“¢^A : Semantics ğ“”^A ğ“œ^A} {ğ“¢^B : Semantics ğ“”^B ğ“œ^B} {ğ“¢^C : Semantics ğ“”^C ğ“œ^C} {ğ“”^Râ€¿BC : {Î“ : Con} {Ïƒ : ty} (e^B : ğ“”^B Î“ Ïƒ) (e^C : ğ“”^C Î“ Ïƒ) â†’ Set â„“^REB} {ğ“”^R : {Î˜ Î” Î“ : Con} (Ï^A : Î” [ ğ“”^A ] Î“) (Ï^B : Î˜ [ ğ“”^B ] Î”) (Ï^C : Î˜ [ ğ“”^C ] Î“) â†’ Set â„“^RE} {ğ“œ^R : {Î“ : Con} {Ïƒ : ty} (mB : ğ“œ^B Î“ Ïƒ) (mC : ğ“œ^C Î“ Ïƒ) â†’ Set â„“^RM} (fusable : Fusable ğ“¢^A ğ“¢^B ğ“¢^C ğ“”^Râ€¿BC ğ“”^R ğ“œ^R) where
  open Fusable fusable

  lemma :  {Î“ Î” Î˜ : Con} {Ïƒ : ty} (t : Î“ âŠ¢ Ïƒ) {Ï^A : Î” [ ğ“”^A ] Î“} {Ï^B : Î˜ [ ğ“”^B ] Î”} {Ï^C : Î˜ [ ğ“”^C ] Î“} (Ï^R : ğ“”^R Ï^A Ï^B Ï^C) â†’
           ğ“œ^R (ğ“¢^B âŠ¨âŸ¦ reify^A (ğ“¢^A âŠ¨âŸ¦ t âŸ§ Ï^A) âŸ§ Ï^B) (ğ“¢^C âŠ¨âŸ¦ t âŸ§ Ï^C)
\end{code}
\AgdaHide{
\begin{code}
  lemma (`var v)       Ï^R = RâŸ¦varâŸ§ v Ï^R
  lemma (f `$ t)       Ï^R = RâŸ¦$âŸ§ f t Ï^R (lemma f Ï^R) (lemma t Ï^R)
  lemma (`Î» t)         Ï^R = RâŸ¦Î»âŸ§ t Ï^R $ Î» inc u^R â†’ lemma t (ğ“”^Râ€¿âˆ™ (ğ“”^Râ€¿wk inc Ï^R) u^R)
  lemma `âŸ¨âŸ©            Ï^R = RâŸ¦âŸ¨âŸ©âŸ§ Ï^R
  lemma `tt            Ï^R = RâŸ¦ttâŸ§ Ï^R
  lemma `ff            Ï^R = RâŸ¦ffâŸ§ Ï^R
  lemma (`ifte b l r)  Ï^R = RâŸ¦ifteâŸ§ b l r Ï^R (lemma b Ï^R) (lemma l Ï^R) (lemma r Ï^R)
\end{code}}

\subsubsection{The Special Case of Syntactic Semantics}

Given that \AR{Syntactic} semantics use a lot of constructors
as their own semantic counterpart, it is possible to generate
evidence of them being fusable with much fewer assumptions.
We isolate them and prove the result generically in order to
avoid repeating ourselves.
A \AR{SyntacticFusable} record packs the evidence necessary to
prove that the \AR{Syntactic} semantics \AB{synA} and \AB{syn^B}
can be fused using the \AR{Syntactic} semantics \AB{syn^C}. It
is indexed by these three \AR{Syntactic}s as well as two relations
corresponding to the \AB{ğ“”^R_{BC}} and \AB{ğ“”^R} ones of the
\AR{Fusable} framework.

It contains the same \ARF{ğ“”^Râ€¿âˆ™}, \ARF{ğ“”^Râ€¿wk} and \ARF{RâŸ¦varâŸ§}
fields as a \AR{Fusable} as well as a fourth one (\ARF{embed^{BC}})
saying that \AB{synB} and \AB{synC}'s respective \ARF{embed}s are
producing related values.

\AgdaHide{
\begin{code}
record SyntacticFusable
  {â„“^EA â„“^EB â„“^EC â„“^REBC â„“^RE : Level} {ğ“”^A : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“^EA} {ğ“”^B : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“^EB} {ğ“”^C : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“^EC} (synA : Syntactic ğ“”^A)
  (synB : Syntactic ğ“”^B)
  (synC : Syntactic ğ“”^C)
  (ğ“”^Râ€¿BC : {Î“ : Con} {Ïƒ : ty} (e^B : ğ“”^B Î“ Ïƒ) (e^C : ğ“”^C Î“ Ïƒ) â†’ Set â„“^REBC)
  (ğ“”^R : {Î˜ Î” Î“ : Con} (Ï^A : Î” [ ğ“”^A ] Î“) (Ï^B : Î˜ [ ğ“”^B ] Î”) (Ï^C : Î˜ [ ğ“”^C ] Î“) â†’ Set â„“^RE)
  : Set (â„“^RE âŠ” â„“^REBC âŠ” â„“^EC âŠ” â„“^EB âŠ” â„“^EA)
  where
  module Syn^A = Syntactic synA
  module Syn^B = Syntactic synB
  module Syn^C = Syntactic synC
  field
    ğ“”^Râ€¿âˆ™ : ({Î“ Î” Î˜ : Con} {Ïƒ : ty} {Ï^A : Î” [ ğ“”^A ] Î“} {Ï^B : Î˜ [ ğ“”^B ] Î”} {Ï^C : Î˜ [ ğ“”^C ] Î“}
               {u^B : ğ“”^B Î˜ Ïƒ} {u^C : ğ“”^C Î˜ Ïƒ} (Ï^R : ğ“”^R Ï^A Ï^B Ï^C) (u^R : ğ“”^Râ€¿BC u^B u^C) â†’
               ğ“”^R ([ ğ“”^A ] wk[ Syn^A.wk ] (step refl) Ï^A `âˆ™ Syn^A.embed Ïƒ zero)
                      ([ ğ“”^B ] Ï^B `âˆ™ u^B)
                      ([ ğ“”^C ] Ï^C `âˆ™ u^C))
    ğ“”^Râ€¿wk : {Î“ Î” Î˜ E : Con} (inc : Î˜ âŠ† E)
               {Ï^A : Î” [ ğ“”^A ] Î“} {Ï^B : Î˜ [ ğ“”^B ] Î”} {Ï^C : Î˜ [ ğ“”^C ] Î“} (Ï^R : ğ“”^R Ï^A Ï^B Ï^C) â†’
               ğ“”^R Ï^A(wk[ Syn^B.wk ] inc Ï^B) (wk[ Syn^C.wk ] inc Ï^C)
    RâŸ¦varâŸ§  : {Î“ Î” Î˜ : Con} {Ïƒ : ty} (v : Ïƒ âˆˆ Î“) {Ï^A : Î” [ ğ“”^A ] Î“} {Ï^B : Î˜ [ ğ“”^B ] Î”} {Ï^C : Î˜ [ ğ“”^C ] Î“}
              (Ï^R : ğ“”^R Ï^A Ï^B Ï^C) â†’
              syntactic synB âŠ¨âŸ¦ syntactic synA âŠ¨âŸ¦ `var v âŸ§ Ï^A âŸ§ Ï^B â‰¡ syntactic synC âŠ¨âŸ¦ `var v âŸ§ Ï^C
\end{code}}
\begin{code}
    embed^BC : {Î“ : Con} {Ïƒ : ty} â†’ ğ“”^Râ€¿BC  {Î“ âˆ™ Ïƒ} (Syn^B.embed Ïƒ zero) (Syn^C.embed Ïƒ zero)
\end{code}

The important result is that given a \AR{SyntacticFusable} relating
three \AR{Syntactic} semantics, one can deliver a \AR{Fusable} relating
the corresponding \AR{Semantics} where \AB{ğ“œ^R} is the propositional
equality.

\begin{code}
syntacticFusable :  {â„“^EA â„“^EB â„“^EC â„“^RE â„“^REBC : Level} {ğ“”^A : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“^EA} {ğ“”^B : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“^EB} {ğ“”^C : (Î“ : Con) (Ïƒ : ty) â†’ Set â„“^EC} {syn^A : Syntactic ğ“”^A} {syn^B : Syntactic ğ“”^B} {syn^C : Syntactic ğ“”^C} {ğ“”^Râ€¿BC : {Î“ : Con} {Ïƒ : ty} (e^B : ğ“”^B Î“ Ïƒ) (e^C : ğ“”^C Î“ Ïƒ) â†’ Set â„“^REBC} {ğ“”^R : {Î˜ Î” Î“ : Con} (Ï^A : Î” [ ğ“”^A ] Î“) (Ï^B : Î˜ [ ğ“”^B ] Î”) (Ï^C : Î˜ [ ğ“”^C ] Î“) â†’ Set â„“^RE} (syn^R : SyntacticFusable syn^A syn^B syn^C ğ“”^Râ€¿BC ğ“”^R) â†’
  Fusable (syntactic syn^A) (syntactic syn^B) (syntactic syn^C) ğ“”^Râ€¿BC ğ“”^R _â‰¡_
\end{code}
\AgdaHide{
\begin{code}
syntacticFusable synF =
  let open SyntacticFusable synF in
  record
    { reify^A    = id
    ; ğ“”^Râ€¿âˆ™   = ğ“”^Râ€¿âˆ™
    ; ğ“”^Râ€¿wk  = ğ“”^Râ€¿wk
    ; RâŸ¦varâŸ§    = RâŸ¦varâŸ§
    ; RâŸ¦$âŸ§      = Î» f t Ï^R â†’ PEq.congâ‚‚ _`$_
    ; RâŸ¦Î»âŸ§      = Î» t Ï^R r â†’ PEq.cong `Î» (r (step refl) embed^BC)
    ; RâŸ¦âŸ¨âŸ©âŸ§     = Î» Ï^R â†’ PEq.refl
    ; RâŸ¦ttâŸ§     = Î» Ï^R â†’ PEq.refl
    ; RâŸ¦ffâŸ§     = Î» Ï^R â†’ PEq.refl
    ; RâŸ¦ifteâŸ§   = Î» b l r Ï^R eqb eql â†’ PEq.congâ‚‚ (uncurry `ifte) (PEq.congâ‚‚ _,_ eqb eql)
    }

`var-inj : {Î“ : Con} {Ïƒ : ty} {prâ‚ prâ‚‚ : Ïƒ âˆˆ Î“} (eq : (Î“ âŠ¢ Ïƒ âˆ‹ `var prâ‚) â‰¡ `var prâ‚‚) â†’ prâ‚ â‰¡ prâ‚‚
`var-inj PEq.refl = PEq.refl
\end{code}}

It is then trivial to prove that \AR{Renaming} can be fused with itself
to give rise to another renaming (obtained by composing the two context
inclusions): \ARF{ğ“”^Râ€¿âˆ™} uses \AF{[\_,\_]}, a case-analysis combinator
for \AB{Ïƒ} \AD{âˆˆ} (\AB{Î“} \AIC{â€µâˆ™} Ï„) distinguishing the case where \AB{Ïƒ}
\AD{âˆˆ} \AB{Î“} and the one where \AB{Ïƒ} equals \AB{Ï„}, whilst the other connectives
are either simply combining induction hypotheses using the congruence of
propositional equality or even simply its reflexivity (the two \ARF{embed}s
we use are identical: they are both the one of \AF{syntacticRenaming} hence
why \ARF{embed^{BC}} is so simple).

\begin{code}
RenamingFusable :
  SyntacticFusable  syntacticRenaming syntacticRenaming syntacticRenaming
                    _â‰¡_ (Î» Ï^A Ï^B Ï^C â†’ âˆ€ Ïƒ pr â†’ Ï^B Ïƒ (Ï^A Ïƒ pr) â‰¡ Ï^C Ïƒ pr)
RenamingFusable = record
  { ğ“”^Râ€¿âˆ™     = Î» Ï^R eq â†’ [ eq , Ï^R ]
  ; ğ“”^Râ€¿wk    = Î» inc Ï^R Ïƒ pr â†’ PEq.cong (inc Ïƒ) (Ï^R Ïƒ pr)
  ; RâŸ¦varâŸ§    = Î» v Ï^R â†’ PEq.cong `var (Ï^R _ v)
  ; embed^BC  = PEq.refl }
\end{code}

Similarly, a \AR{Substitution} following a \AR{Renaming} is equivalent to
a \AR{Substitution} where the evaluation environment is the composition of
the two previous ones.

\begin{code}
RenamingSubstitutionFusable :
  SyntacticFusable syntacticRenaming syntacticSubstitution syntacticSubstitution
  _â‰¡_ (Î» Ï^A Ï^B Ï^C â†’ âˆ€ Ïƒ pr â†’ Ï^B Ïƒ (Ï^A Ïƒ pr) â‰¡ Ï^C Ïƒ pr)
\end{code}
\AgdaHide{
\begin{code}
RenamingSubstitutionFusable =
  record { ğ“”^Râ€¿âˆ™   = Î» Ï^R eq â†’ [ eq , Ï^R ]
         ; ğ“”^Râ€¿wk  = Î» inc Ï^R Ïƒ pr â†’ PEq.cong (Renaming âŠ¨âŸ¦_âŸ§ inc) (Ï^R Ïƒ pr)
         ; RâŸ¦varâŸ§    = Î» v Ï^R â†’ Ï^R _ v
         ; embed^BC   = PEq.refl }
\end{code}}

Using the newly established fact about fusing two \AR{Renamings} together,
we can establish that a \AR{Substitution} followed by a \AR{Renaming} is
equivalent to a \AR{Substitution} where the elements in the evaluation
environment have been renamed.

\begin{code}
SubstitutionRenamingFusable :
  SyntacticFusable syntacticSubstitution syntacticRenaming syntacticSubstitution
  (Î» v t â†’ `var v â‰¡ t) (Î» Ï^A Ï^B Ï^C â†’ âˆ€ Ïƒ pr â†’ Renaming âŠ¨âŸ¦ Ï^A Ïƒ pr âŸ§ Ï^B â‰¡ Ï^C Ïƒ pr)
\end{code}
\AgdaHide{
\begin{code}
SubstitutionRenamingFusable =
  let module RenRen = Fusion (syntacticFusable RenamingFusable) in
  record { ğ“”^Râ€¿âˆ™   = Î» {_} {_} {_} {_} {Ï^A} {Ï^B} {Ï^C} Ï^R eq â†’ [ eq , (Î» Ïƒ pr â†’
                         PEq.trans (RenRen.lemma (Ï^A Ïƒ pr) (Î» _ _ â†’ PEq.refl))
                                   (Ï^R Ïƒ pr)) ]
         ; ğ“”^Râ€¿wk  = Î» inc {Ï^A} {Ï^B} {Ï^C} Ï^R Ïƒ pr â†’
                         PEq.trans (PEq.sym (RenRen.lemma (Ï^A Ïƒ pr) (Î» _ _ â†’ PEq.refl)))
                                   (PEq.cong (Renaming âŠ¨âŸ¦_âŸ§ inc) (Ï^R Ïƒ pr))
         ; RâŸ¦varâŸ§    = Î» v Ï^R â†’ Ï^R _ v
         ; embed^BC   = PEq.refl }
\end{code}}

Finally, using the fact that we now know how to fuse a \AR{Substitution}
and a \AR{Renaming} together no matter in which order they're performed,
we can prove that two \AR{Substitution}s can be fused together.

\begin{code}
SubstitutionFusable :
  SyntacticFusable syntacticSubstitution syntacticSubstitution syntacticSubstitution
  _â‰¡_ (Î» Ï^A Ï^B Ï^C â†’ âˆ€ Ïƒ pr â†’ Substitution âŠ¨âŸ¦ Ï^A Ïƒ pr âŸ§ Ï^B â‰¡ Ï^C Ïƒ pr)
\end{code}
\AgdaHide{
\begin{code}
SubstitutionFusable =
  let module RenSubst = Fusion (syntacticFusable RenamingSubstitutionFusable)
      module SubstRen = Fusion (syntacticFusable SubstitutionRenamingFusable) in
  record { ğ“”^Râ€¿âˆ™   = Î» {_} {_} {_} {_} {Ï^A} {Ï^B} {Ï^C} Ï^R eq â†’ [ eq , (Î» Ïƒ pr â†’
                         PEq.trans (RenSubst.lemma (Ï^A Ïƒ pr) (Î» _ _ â†’ PEq.refl))
                                   (Ï^R Ïƒ pr)) ]
         ; ğ“”^Râ€¿wk  = Î» inc {Ï^A} {Ï^B} {Ï^C} Ï^R Ïƒ pr â†’
                         PEq.trans (PEq.sym (SubstRen.lemma (Ï^A Ïƒ pr) (Î» _ _ â†’ PEq.refl)))
                                   (PEq.cong (Renaming âŠ¨âŸ¦_âŸ§ inc) (Ï^R Ïƒ pr))
         ; RâŸ¦varâŸ§    = Î» v Ï^R â†’ Ï^R _ v
         ; embed^BC   = PEq.refl }

ifteRenNorm :
      {Î“ Î” Î˜ : Con} {Ïƒ : ty} (b : Î“ âŠ¢ `Bool) (l r : Î“ âŠ¢ Ïƒ)
      {Ï^A : Î” [ flip _âˆˆ_ ] Î“} {Ï^B : Î˜ [ _âŠ¨^Î²Î¹Î¾Î·_ ] Î”}
      {Ï^C : Î˜ [ _âŠ¨^Î²Î¹Î¾Î·_ ] Î“} â†’
      (Ï^R : (Ïƒ : ty) (pr : Ïƒ âˆˆ Î“) â†’ EQREL Î˜ Ïƒ (Ï^B Ïƒ (Ï^A Ïƒ pr)) (Ï^C Ïƒ pr)) â†’
      Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ id (Renaming âŠ¨âŸ¦ b âŸ§ Ï^A) âŸ§ Ï^B â‰¡
      Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ b âŸ§ Ï^C â†’
      EQREL Î˜ Ïƒ (Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ id (Renaming âŠ¨âŸ¦ l âŸ§ Ï^A) âŸ§ Ï^B)
      (Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ l âŸ§ Ï^C) â†’
      EQREL Î˜ Ïƒ (Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ id (Renaming âŠ¨âŸ¦ r âŸ§ Ï^A) âŸ§ Ï^B)
      (Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ r âŸ§ Ï^C) â†’
      EQREL Î˜ Ïƒ
      (Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ id (Renaming âŠ¨âŸ¦ `ifte b l r âŸ§ Ï^A) âŸ§ Ï^B)
      (Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ `ifte b l r âŸ§ Ï^C)
ifteRenNorm b l r {Ï^A} {Ï^B} {Ï^C} Ï^R eqb eql eqr
  with Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ Renaming âŠ¨âŸ¦ b âŸ§ Ï^A âŸ§ Ï^B
     | Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ b âŸ§ Ï^C
ifteRenNorm b l r Ï^R PEq.refl eql eqr | `embed _ t | `embed _ .t =
  reflect^EQREL _ (PEq.congâ‚‚ (uncurry `ifte) (PEq.congâ‚‚ _,_ PEq.refl (reify^EQREL _ eql)) (reify^EQREL _ eqr))
ifteRenNorm b l r Ï^R () eql eqr | `embed _ t | `tt
ifteRenNorm b l r Ï^R () eql eqr | `embed _ t | `ff
ifteRenNorm b l r Ï^R () eql eqr | `tt | `embed _ t
ifteRenNorm b l r Ï^R PEq.refl eql eqr | `tt | `tt = eql
ifteRenNorm b l r Ï^R () eql eqr | `tt | `ff
ifteRenNorm b l r Ï^R () eql eqr | `ff | `embed _ t
ifteRenNorm b l r Ï^R () eql eqr | `ff | `tt
ifteRenNorm b l r Ï^R PEq.refl eql eqr | `ff | `ff = eqr
\end{code}}

These four lemmas are usually painfully proven one after the other. Here
we managed to discharge them by simply instantiating our framework four
times in a row, using the former instances to discharge the constraints
arising in the later ones. But we are not at all limited to proving
statements about \AR{Syntactic}s only.

\subsubsection{Example of Fusable Semantics}

The most simple example of \AR{Fusable} \AR{Semantics} involving a non
\AR{Syntactic} one is probably the proof that \AR{Renaming} followed
by \AR{Normalise^{Î²Î¹Î¾Î·}} is equivalent to Normalisation by Evaluation
where the environment has been tweaked.

\begin{code}
RenamingNormaliseFusable :
  Fusable Renaming Normalise^Î²Î¹Î¾Î· Normalise^Î²Î¹Î¾Î·
  (EQREL _ _)
  (Î» Ï^A Ï^B Ï^C â†’ âˆ€ Ïƒ pr â†’ EQREL _ Ïƒ (Ï^B Ïƒ (Ï^A Ïƒ pr)) (Ï^C Ïƒ pr))
  (EQREL _ _)
\end{code}
\AgdaHide{
\begin{code}
RenamingNormaliseFusable =
  record
    { reify^A   = id
    ; ğ“”^Râ€¿âˆ™  = Î» Ï^R u^R â†’ [ u^R , Ï^R ]
    ; ğ“”^Râ€¿wk = Î» inc Ï^R â†’ Î» Ïƒ pr â†’ wk^EQREL Ïƒ inc (Ï^R Ïƒ pr)
    ; RâŸ¦varâŸ§   = Î» v Ï^R â†’ Ï^R _ v
    ; RâŸ¦$âŸ§     = Î» _ _ _ r â†’ r refl
    ; RâŸ¦Î»âŸ§     = Î» _ _ r â†’ r
    ; RâŸ¦âŸ¨âŸ©âŸ§    = Î» _ â†’ âŸ¨âŸ©
    ; RâŸ¦ttâŸ§    = Î» _ â†’ PEq.refl
    ; RâŸ¦ffâŸ§    = Î» _ â†’ PEq.refl
    ; RâŸ¦ifteâŸ§  = ifteRenNorm
    }


ifteSubstNorm :
     {Î“ Î” Î˜ : Con} {Ïƒ : ty} (b : Î“ âŠ¢ `Bool) (l r : Î“ âŠ¢ Ïƒ)
      {Ï^A : Î” [ _âŠ¢_ ] Î“} {Ï^B : Î˜ [ _âŠ¨^Î²Î¹Î¾Î·_ ] Î”}
      {Ï^C : Î˜ [ _âŠ¨^Î²Î¹Î¾Î·_ ] Î“} â†’
      ((Ïƒâ‚ : ty) (pr : Ïƒâ‚ âˆˆ Î”) â†’ EQREL Î˜ Ïƒâ‚ (Ï^B Ïƒâ‚ pr) (Ï^B Ïƒâ‚ pr)) Ã—
      ((Ïƒâ‚ : ty) (pr : Ïƒâ‚ âˆˆ Î“) {Î˜â‚ : Con} (inc : Î˜ âŠ† Î˜â‚) â†’
       EQREL Î˜â‚ Ïƒâ‚
       (Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ Ï^A Ïƒâ‚ pr âŸ§
        (Î» Ïƒâ‚‚ prâ‚ â†’ wk^Î²Î¹Î¾Î· Ïƒâ‚‚ inc $ Ï^B Ïƒâ‚‚ prâ‚))
       (wk^Î²Î¹Î¾Î· Ïƒâ‚ inc $ Ï^C Ïƒâ‚ pr))
      Ã—
      ((Ïƒâ‚ : ty) (pr : Ïƒâ‚ âˆˆ Î“) â†’
       EQREL Î˜ Ïƒâ‚ (Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ Ï^A Ïƒâ‚ pr âŸ§ Ï^B) (Ï^C Ïƒâ‚ pr)) â†’
      Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ id (Substitution âŠ¨âŸ¦ b âŸ§ Ï^A) âŸ§ Ï^B â‰¡
      Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ b âŸ§ Ï^C â†’
      EQREL Î˜ Ïƒ (Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ id (Substitution âŠ¨âŸ¦ l âŸ§ Ï^A) âŸ§ Ï^B)
      (Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ l âŸ§ Ï^C) â†’
      EQREL Î˜ Ïƒ (Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ id (Substitution âŠ¨âŸ¦ r âŸ§ Ï^A) âŸ§ Ï^B)
      (Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ r âŸ§ Ï^C) â†’
      EQREL Î˜ Ïƒ
      (Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ id (Substitution âŠ¨âŸ¦ `ifte b l r âŸ§ Ï^A) âŸ§ Ï^B)
      (Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ `ifte b l r âŸ§ Ï^C)
ifteSubstNorm b l r {Ï^A} {Ï^B} {Ï^C} Ï^R eqb eql eqr
  with Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ Substitution âŠ¨âŸ¦ b âŸ§ Ï^A âŸ§ Ï^B
     | Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ b âŸ§ Ï^C
ifteSubstNorm b l r Ï^R PEq.refl eql eqr | `embed _ t | `embed _ .t =
  reflect^EQREL _ (PEq.congâ‚‚ (uncurry `ifte) (PEq.congâ‚‚ _,_ PEq.refl (reify^EQREL _ eql)) (reify^EQREL _ eqr))
ifteSubstNorm b l r Ï^R () eql eqr | `embed _ t | `tt
ifteSubstNorm b l r Ï^R () eql eqr | `embed _ t | `ff
ifteSubstNorm b l r Ï^R () eql eqr | `tt | `embed _ t
ifteSubstNorm b l r Ï^R PEq.refl eql eqr | `tt | `tt = eql
ifteSubstNorm b l r Ï^R () eql eqr | `tt | `ff
ifteSubstNorm b l r Ï^R () eql eqr | `ff | `embed _ t
ifteSubstNorm b l r Ï^R () eql eqr | `ff | `tt
ifteSubstNorm b l r Ï^R PEq.refl eql eqr | `ff | `ff = eqr

wk-refl : {Î“ : Con} (Ïƒ : ty) {T U : Î“ âŠ¨^Î²Î¹Î¾Î· Ïƒ} â†’
          EQREL Î“ Ïƒ T U â†’ EQREL Î“ Ïƒ (wk^Î²Î¹Î¾Î· Ïƒ refl T) U
wk-refl `Unit     eq = âŸ¨âŸ©
wk-refl `Bool     eq = PEq.trans (wk^nf-refl _) eq
wk-refl (Ïƒ `â†’ Ï„)  eq = eq

wk^2 : {Î˜ Î” Î“ : Con} (Ïƒ : ty) (incâ‚ : Î“ âŠ† Î”) (incâ‚‚ : Î” âŠ† Î˜) {T U : Î“ âŠ¨^Î²Î¹Î¾Î· Ïƒ} â†’
       EQREL Î“ Ïƒ T U â†’ EQREL Î˜ Ïƒ (wk^Î²Î¹Î¾Î· Ïƒ incâ‚‚ $ wk^Î²Î¹Î¾Î· Ïƒ incâ‚ T) (wk^Î²Î¹Î¾Î· Ïƒ (trans incâ‚ incâ‚‚) U)
wk^2 `Unit     incâ‚ incâ‚‚ eq = âŸ¨âŸ©
wk^2 `Bool     incâ‚ incâ‚‚ eq = PEq.trans (wk^nf-trans incâ‚ incâ‚‚ _) (PEq.cong (wk^nf (trans incâ‚ incâ‚‚)) eq)
wk^2 (Ïƒ `â†’ Ï„)  incâ‚ incâ‚‚ eq = Î» incâ‚ƒ â†’ eq (trans incâ‚ $ trans incâ‚‚ incâ‚ƒ)
\end{code}}

Then, we use the framework to prove that to \AR{Normalise^{Î²Î¹Î¾Î·}} by
Evaluation after a \AR{Substitution} amounts to normalising the original
term where the substitution has been evaluated first. The constraints
imposed on the environments might seem quite restrictive but they are
actually similar to the Uniformity condition described by C. Coquand~\cite{coquand2002formalised}
in her detailed account of Normalisation by Evaluation for a simply-typed
Î»-calculus with explicit substitutions.


\begin{code}
SubstitutionNormaliseFusable :
  Fusable  Substitution
           Normalise^Î²Î¹Î¾Î·
           Normalise^Î²Î¹Î¾Î·
           (EQREL _ _)
           (Î» Ï^A Ï^B Ï^C â†’ ((Ïƒ : ty) (pr : Ïƒ âˆˆ _) â†’ EQREL _ Ïƒ (Ï^B Ïƒ pr) (Ï^B Ïƒ pr))
                      Ã— ((Ïƒ : ty) (pr : Ïƒ âˆˆ _) {Î˜ : Con} (inc : _ âŠ† Î˜) â†’
                         EQREL Î˜ Ïƒ (Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ Ï^A Ïƒ pr âŸ§ (Î» Ïƒ pr â†’ wk^Î²Î¹Î¾Î· Ïƒ inc $ Ï^B Ïƒ pr))
                                   (wk^Î²Î¹Î¾Î· Ïƒ inc $ Ï^C Ïƒ pr))
                      Ã— ((Ïƒ : ty) (pr : Ïƒ âˆˆ _) â†’ EQREL _ Ïƒ (Normalise^Î²Î¹Î¾Î· âŠ¨âŸ¦ Ï^A Ïƒ pr âŸ§ Ï^B) (Ï^C Ïƒ pr)))
           (EQREL _ _)
\end{code}
\AgdaHide{
\begin{code}
SubstitutionNormaliseFusable =
  let module RenNorm = Fusion RenamingNormaliseFusable
      module EqNorm  = Synchronised SynchronisableNormalise in
  record
    { reify^A   = id
    ; ğ“”^Râ€¿âˆ™  = Î» {_} {_} {_} {_} {Ï^A} {Ï^B} {Ï^C} Ï^R u^R â†’
                     [ reflEQREL _ u^R , projâ‚ Ï^R ]
                   , [ (Î» {Î˜} inc â†’ wk^EQREL _ inc u^R)
                     , (Î» Ïƒ pr {Î˜} inc â†’
                       transEQREL Ïƒ (RenNorm.lemma (Ï^A Ïƒ pr)
                                                    (Î» Ïƒ pr â†’ wk^EQREL Ïƒ inc (projâ‚ Ï^R Ïƒ pr)))
                                    ((projâ‚ âˆ˜ projâ‚‚) Ï^R Ïƒ pr inc)) ]
                     , [ u^R , (Î» Ïƒ pr â†’ transEQREL Ïƒ (RenNorm.lemma (Ï^A Ïƒ pr) (projâ‚ Ï^R))
                                          ((projâ‚‚ âˆ˜ projâ‚‚) Ï^R Ïƒ pr)) ]
    ; ğ“”^Râ€¿wk = Î» inc {Ï^A} Ï^R â†’
                            (Î» Ïƒ pr â†’ wk^EQREL Ïƒ inc (projâ‚ Ï^R Ïƒ pr))
                          , (Î» Ïƒ pr {Î˜} incâ€² â†’
                               transEQREL Ïƒ (EqNorm.lemma (Ï^A Ïƒ pr)
                               (Î» Ïƒ pr â†’ transEQREL Ïƒ (wk^2 Ïƒ inc incâ€² (projâ‚ Ï^R Ïƒ pr))
                                                      (wk^EQREL Ïƒ (trans inc incâ€²) (projâ‚ Ï^R Ïƒ pr))))
                               (transEQREL Ïƒ ((projâ‚ âˆ˜ projâ‚‚) Ï^R Ïƒ pr (trans inc incâ€²))
                               (symEQREL Ïƒ (wk^2 Ïƒ inc incâ€² (reflEQREL Ïƒ (symEQREL Ïƒ $ (projâ‚‚ âˆ˜ projâ‚‚) Ï^R Ïƒ pr))))))
                          , (Î» Ïƒ pr â†’ (projâ‚ âˆ˜ projâ‚‚) Ï^R Ïƒ pr inc)
    ; RâŸ¦varâŸ§   = Î» v Ï^R â†’ (projâ‚‚ âˆ˜ projâ‚‚) Ï^R _ v
    ; RâŸ¦$âŸ§     = Î» _ _ _ r â†’ r refl
    ; RâŸ¦Î»âŸ§     = Î» _ _ r â†’ r
    ; RâŸ¦âŸ¨âŸ©âŸ§    = Î» _ â†’ âŸ¨âŸ©
    ; RâŸ¦ttâŸ§    = Î» _ â†’ PEq.refl
    ; RâŸ¦ffâŸ§    = Î» _ â†’ PEq.refl
    ; RâŸ¦ifteâŸ§  = ifteSubstNorm
    }

both : {A B : Set} {aâ‚ aâ‚‚ : A} {bâ‚ bâ‚‚ : B} (eq : (A Ã— B âˆ‹ aâ‚ , bâ‚) â‰¡ (aâ‚‚ , bâ‚‚)) â†’ aâ‚ â‰¡ aâ‚‚ Ã— bâ‚ â‰¡ bâ‚‚
both PEq.refl = PEq.refl , PEq.refl

âˆ·-inj : {A : Set} {a b : A} {as bs : âˆ (Stream A)} (eq : (Stream A âˆ‹ a âˆ· as) â‰¡ b âˆ· bs) â†’ a â‰¡ b Ã— as â‰¡ bs
âˆ·-inj PEq.refl = PEq.refl , PEq.refl
\end{code}}

Finally, we may use the notion of \AR{Fusable} to prove that our
definition of pretty-printing ignores \AR{Renamings}. In other
words, as long as the names provided for the free variables are
compatible after the renaming and as long as the name supplies
are equal then the string produced, as well as the state of the
name supply at the end of the process, are equal.

\begin{code}
RenamingPrettyPrintingFusable :
  Fusable Renaming Printing Printing
  _â‰¡_
  (Î» Ï^A Ï^B Ï^C â†’ âˆ€ Ïƒ pr â†’ Ï^B Ïƒ (Ï^A Ïƒ pr) â‰¡ Ï^C Ïƒ pr)
  (Î» p q â†’ âˆ€ {namesâ‚ namesâ‚‚} â†’ namesâ‚ â‰¡ namesâ‚‚ â†’ runPrinter p namesâ‚ â‰¡ runPrinter q namesâ‚‚)
\end{code}
\AgdaHide{
\begin{code}
RenamingPrettyPrintingFusable = record
  { reify^A   = id
  ; ğ“”^Râ€¿âˆ™   = Î» Ï^R eq â†’ [ eq , Ï^R ]
  ; ğ“”^Râ€¿wk  = Î» _ Ï^R Ïƒ pr â†’ PEq.cong (mkName âˆ˜ runName) (Ï^R Ïƒ pr)
  ; RâŸ¦varâŸ§   = Î» v Ï^R â†’ PEq.congâ‚‚ (Î» n ns â†’ runName n , ns) (Ï^R _ v)
  ; RâŸ¦Î»âŸ§     = Î» t Ï^R r â†’ Î» { {nâ‚ âˆ· nâ‚s} {nâ‚‚ âˆ· nâ‚‚s} eq â†’
                        let (neq   , nseq) = âˆ·-inj eq
                            (ihstr , ihns) = both (r (step refl) (PEq.cong mkName neq) (PEq.cong â™­ nseq))
                        in PEq.congâ‚‚ _,_ (PEq.congâ‚‚ (Î» n str â†’ "Î»" ++ n ++ ". " ++ str) neq ihstr) ihns }
  ; RâŸ¦$âŸ§     = Î» f t {Ï^A} {Ï^B} {Ï^C} Ï^R ihf iht eq â†’
                        let (ihstrf , eqâ‚) = both (ihf eq)
                            (ihstrt , eqâ‚‚) = both (iht eqâ‚)
                        in PEq.congâ‚‚ _,_ (PEq.congâ‚‚ (Î» strf strt â†’ strf ++ " (" ++ strt ++ ")") ihstrf ihstrt) eqâ‚‚
  ; RâŸ¦âŸ¨âŸ©âŸ§    = Î» _ â†’ PEq.cong _
  ; RâŸ¦ttâŸ§    = Î» _ â†’ PEq.cong _
  ; RâŸ¦ffâŸ§    = Î» _ â†’ PEq.cong _
  ; RâŸ¦ifteâŸ§  = Î» b l r {Ï^A} {Ï^B} {Ï^C} Ï^R ihb ihl ihr eq â†’
                       let (ihstrb , eqâ‚) = both (ihb eq)
                           (ihstrl , eqâ‚‚) = both (ihl eqâ‚)
                           (ihstrr , eqâ‚ƒ) = both (ihr eqâ‚‚)
                       in PEq.congâ‚‚ _,_ (PEq.congâ‚‚ (Î» strb strlr â†’ "if (" ++ strb ++ ") then (" ++ strlr)
                                        ihstrb (PEq.congâ‚‚ (Î» strl strr â†’ strl ++ ") else (" ++ strr ++ ")")
                                        ihstrl ihstrr)) eqâ‚ƒ }

tailComm : (Î” Î“ : Con) {names : Stream String} â†’
           tail (projâ‚‚ (nameContext Î” Î“ names)) â‰¡ projâ‚‚ (nameContext Î” Î“ (tail names))
tailComm Î” Îµ        = PEq.refl
tailComm Î” (Î“ âˆ™ _)  = PEq.cong tail (tailComm Î” Î“)

proof : (Î” Î“ : Con) {names : Stream String} â†’ projâ‚‚ (nameContext Î” Î“ names) â‰¡ Stream.drop (size Î“) names
proof Î” Îµ       = PEq.refl
proof Î” (Î“ âˆ™ _) = Î» { {_ âˆ· names} â†’ PEq.trans (tailComm Î” Î“) (proof Î” Î“) }
\end{code}}
A direct corollary is that pretty printing a weakened closed term
amounts to pretty printing the term itself in a dummy environment.

\begin{code}
PrettyRenaming : {Î“ : Con} {Ïƒ : ty} (t : Îµ âŠ¢ Ïƒ) (inc : Îµ âŠ† Î“) â†’
  print (wk^âŠ¢ inc t) â‰¡ projâ‚ (runPrinter (Printing âŠ¨âŸ¦ t âŸ§ (Î» _ ())) $ Stream.drop (size Î“) names)
PrettyRenaming {Î“} t inc = PEq.cong projâ‚ (RenPret.lemma t (Î» _ ()) (proof Î“ Î“))
  where module RenPret = Fusion RenamingPrettyPrintingFusable
\end{code}

\section{Conclusion}

We have explained how to make using an inductive family to only represent
the terms of an eDSL which are well-scoped and well-typed by construction
more tractable. We proceeded by factoring out a common notion of \AR{Semantics}
encompassing a wide range of type and scope preserving traversals such as
renaming and substitution, which were already handled by the state of the
art~\cite{mcbride2005type,benton2012strongly}, but also pretty printing, or
various variations on normalisation by evaluation.
Our approach crucially relied on the careful distinction we made between
values in the environment and values in the model, as well as the slight
variation on the usual structure of the semantic counterpart of binders
in Kripke models. Indeed, in our formulation, the domain of a binder's
interpretation is an environment value rather than a model one.

We have then demonstrated that, having this shared structure, one could
further alleviate the implementer's pain by tackling the properties of
these \AR{Semantics} in a similarly abstract approach. We characterised,
using a first logical relation, the traversals which were producing
related outputs provided they were fed related inputs. A more involved
second logical relation gave us a general description of triples of
\AR{Fusable} semantics such that composing the two first ones would
yield an instance of the third one.

\newpage{}
\bibliography{main}

\end{document}
