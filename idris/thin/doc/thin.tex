\documentclass{article}


\usepackage{catchfilebetweentags}
\input{robust-catch}

\usepackage{idris2}

\usepackage{todonotes}
\setuptodonotes{inline}

\newcommand{\typos}{TypOS}
\newcommand{\idris}{Idris 2}
\newcommand{\coq}{Coq}
\newcommand{\agda}{Agda}

\bibliographystyle{alpha}

\begin{document}

\title{Builtin Types viewed as Inductive Families \\
{\large Efficiently Representing Thinnigs in \idris, a case study}}
\author{Guillaume Allais}

\maketitle

\begin{abstract}
  Remembering that types give us a way to make sense of unstructured data stored
  in memory, we demonstrate how to use Quantitative Type Theory to define an
  invariant-rich typechecking time data structure that is guaranteed to compile
  to an efficient runtime one.

  Unlike other approaches, the resulting complexity is entirely predictable, we do
  not require both representations to have the same structure, and yet we are able
  to seamlessly program as if we were using the high-level structure.
\end{abstract}

\section{Introduction}

Dependently typed languages have empowered users to precisely describe their domain
of discourse by using inductive families~\cite{DBLP:journals/fac/Dybjer94}.
%
Programmers can bake crucial invariants directly into their definitions thus refining
both their functions' inputs and outputs.
%
The constrained inputs allow them to only consider the relevant cases during pattern
matching, while the refined outputs guarantee that client code can safely rely on the
invariants being maintained.

\subsection{An Optimisation Example}

However relying on inductive families can have a non-negligible runtime cost.
The prototypical example is probably the lookup function for vectors.

\ExecuteMetaData[Lookup.idr.tex]{vect}

\ExecuteMetaData[Lookup.idr.tex]{fin}

\ExecuteMetaData[Lookup.idr.tex]{vectlookup}

There has already been extensive work on erasure to automatically detect redundant
data~\cite{DBLP:conf/types/BradyMM03} or data that will not be used at
runtime~\cite{DBLP:journals/pacmpl/Tejiscak20}.
%
A Brady-style analysis can solve the quadratic blowup highlighted above by observing
that the natural number a vector is indexed by is entirely determined by the spine of
the vector. In particular, the length of the predecessor does not need to be stored
as part of the constructor: it can be reconstructed as the predecessor of the length
of the overall vector. As a consequence, a vector can be adequately represented at
runtime by a pair of a natural number and a list. Similarly the bounded number can be
adequately represented by a pair of natural number. Putting all of this together,
lookup can be compiled to a function taking two natural number and a list.

\ExecuteMetaData[Lookup.idr.tex]{erasedvectlookup}

A Tejiščák-style analysis can additionally notice that the lookup function never makes
use of the bound's value and drop it. This leads to the lookup function on vectors
being compiled to its partial-looking counterpart acting on lists.

\ExecuteMetaData[Lookup.idr.tex]{finallookup}

Even though this is in our opinion a pretty compelling example, we need to stay
realistic. The compiler needs to be able to map the indexed family to a simpler
datatype that can then be extracted to the target language. If the types have
been simplified, they still have very much the same structure.

\subsection{No Magic Solution}


However even if we are able to obtain a more compact representation of the inductive
family at runtime through enough erasure, this does not guarantee runtime efficiency.
As the \coq{} manual~\cite{Coq:manual} reminds its users, extraction does not magically
optimises away a quadratic multiplication algorithm when extracting unary natural
numbers to an efficient machine representation.
%
\coq{}, \agda{}, and \idris{} all have ad-hoc rules to also replace during compilation
such numeric functions with their counterparts in the target language.
%
However this is not scalable: if we may be willing to extend our trusted core to a
high quality library for unbounded integers, we cannot possibly contemplate replacing
our code only proven correct thanks to complex invariants with a wildly different
untrusted counterpart purely for efficiency reasons.

In this paper we use Quantitative Type
Theory~\cite{DBLP:conf/birthday/McBride16,DBLP:conf/lics/Atkey18}
as implemented in \idris{}~\cite{DBLP:conf/ecoop/Brady21} to bridge the gap between
an invariant-rich but inefficient representation based on an inductive family and
an unsafe but efficient implementation using low-level primitives.
%
Inductive families allow us to \emph{view}~\cite{DBLP:journals/jfp/McBrideM04} the
runtime relevant information encoded in the low-level and efficient representation
as an information-rich compile time data structure. Moreover the quantity annotations
guarantee that this additional information will be erased away during compilation.

\section{Quantitative Type Theory}

\section{Co-de Bruijn representation, cooked two ways}

Using a de Bruijn representation~\cite{MANUAL:journals/math/debruijn72} each variable
points to the binder that introduced it. In a co-de Bruijn
representation~\cite{DBLP:journals/corr/abs-1807-04085} each subterm
selects the variables that stay in scope for that term, and so a variable constructor
ultimately refers to the single variable still in scope by the time it is reached.
%
This representation ensures that we know precisely what the scope of a given term
currently is.

We can recover terms living in arbitrary scopes by pairing a co-de Bruijn term
with a thinning embedding its tight support into the given englobing scope.
\todo{defined CdB}

\todo{application e.g. shrinking}

In order to efficiently represent and traverse terms in co-de Bruijn representation,
we need a compact encoding of thinnings and a cheap composition operator.
\todo{example: opening an application node}

The implementation of \typos~\cite{MANUAL:talk/types/Allais22} uses a co-de Bruijn
representation internally. \todo{explain why}
%
The developpement of the \typos{} language highlights a glaring gap between on the
one hand the experiments done in Agda and on the other the actual implementation
in Haskell.
%
The Agda-based experiments use inductive families that make the key invariants explicit
which helps tracking complex constraints and catches design flaws. The indices guarantee
that we always transform the thinnings appropriately when we add or remove bound variables.
%
The Haskell implementation represents a thinning as a pair of integers and resorts to
explicitly manipulating individual bits. It is not indexed and thus all the invariant
tracking has to be done by hand. This has led to numerous and hard to diagnose bugs.

\idris{} is a bootstrapped language. If we were to use such a co-deBruijn representation
of terms as a replacement for \idris{}'s current core language we would want, and should
be able, to have the best of both worlds.



\section{Related Work}

For historical and ergonomic reasons, idiomatic code in \coq{} tends to center programs
written in a subset of the language quite close to OCaml and then prove properties
about these programs in the runtime irrelevant \texttt{Prop} fragment.
%
This can lead to awkward encodings when the unrefined inputs force the user to consider
cases which ought to be impossible. Common coping strategies involve relaxing the types
to insert a modicum of partiality e.g. returning an option type or taking an additional
input to be used as the default return value.
%
This approach completely misses the point of type-driven development. We benefit a lot
from having as much information as possible available during interactive editing. This
helps tremendously getting the definitions right by ensuring we always maintain vital
invariants thus making invalid states unrepresentable.
%
Thankfully libraries such as Equations~\cite{DBLP:conf/itp/Sozeau10,DBLP:journals/pacmpl/SozeauM19}
can help users write more dependently typed programs, by taking care of the complex
encoding required in \coq{}. A view-based approach similar to ours but using \texttt{Prop}
instead of the zero quantity ought to be possible.

Prior work on erasure~\cite{DBLP:journals/pacmpl/Tejiscak20} has the advantage of
offering a fully automated analysis of the code. The main inconvenient is that users
cannot state explicitly that a piece of data ought to be runtime irrelevant and so
they may end up inadvertently using it which would prevent its erasure.
%
Quantitative Type Theory allows us users to explicitly choose what is and is not
runtime relevant, with the quantity checker keeping us true to our word.
%
This should ensure that the resulting program has a much more predictable complexity.

A somewhat related idea was explored by Brady, McKinna, and Hammond in the context of
circuit design~\cite{DBLP:conf/sfp/BradyMH07}. In their verification work they index
an efficient representation (natural numbers as a list of bits) by its meaning as a
unary natural number. All the operations are correct by construction as witnessed by
the use of their unary counterparts acting as type-level specifications.
%
In the end their algorithms still process the inductive family instead of working
directly with binary numbers. This makes sense in their setting where they construct
circuits and so are explicitly manipulating wires carrying bits.
%
By contrast, in our motivating example we really want to get down to actual (unbounded)
integers.

\todo{Iris}

\section{Future Work}

Our objectives are twofold: we would like to explore more low-level operations and
extend language support for this style of programming.

The \idris{} standard library gave us access to a pure interface to explicitly
manipulate an integer's bits. There is no such thing yet for interacting with a
read-only array for instance.

Our library of efficient operations on thinnings currently suffers from having to
implement annoyingly verbose inversion lemmas. This is caused by the fact that
\idris{} will not let you pattern-match on a runtime irrelevant value in a runtime
relevant context. It should however be safe to do so if all but one branches can
be proven to be impossible, or even more generally, if the information thus obtained
only flows into runtime irrelevant arguments.

\bibliography{thin}

\end{document}
